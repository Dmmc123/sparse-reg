[{"text": "CompSci Weekend SuperThread (January 01, 2021). /r/compsci strives to be the best online community for computer scientists. We moderate posts to keep things on topic.\n\nThis **Weekend SuperThread** provides a discussion area for posts that might be off-topic normally. **Anything Goes:** post your questions, ideas, requests for help, musings, or whatever comes to mind as comments in this thread.\n\n### Pointers\n* If you're looking to answer questions, sort by new comments.\n* If you're looking for answers, sort by top comment.\n* Upvote a question you've answered for visibility.\n* Downvoting is discouraged. Save it for discourteous content only.\n\n### Caveats\n* It's not *truly* \"Anything Goes\". Please follow [Reddiquette](https://www.reddit.com/wiki/reddiquette) and use common sense.\n* Homework help questions are discouraged.", "score": 96}, {"text": "PSA: This is not r/Programming. Quick Clarification on the guidelines. As there's been recently quite the number of rule-breaking posts slipping by, I felt clarifying on a handful of key points would help out a bit (especially as most people use New.Reddit/Mobile, where the FAQ/sidebar isn't visible)\n\n&amp;#x200B;\n\nFirst thing is first, this is ***not a programming specific subreddit***! If the post is a better fit for r/Programming or r/LearnProgramming, that's exactly where it's supposed to be posted in. Unless it involves some aspects of AI/CS, it's relatively better off somewhere else.\n\n&amp;#x200B;\n\nr/ProgrammerHumor: Have a meme or joke relating to CS/Programming that you'd like to share with others? Head over to r/ProgrammerHumor, please.\n\n&amp;#x200B;\n\nr/AskComputerScience: Have a ***genuine*** question in relation to CS that isn't directly asking for homework/assignment help nor someone to do it for you? Head over to r/AskComputerScience.\n\n&amp;#x200B;\n\nr/CsMajors: Have a question in relation to CS academia (**such as \"Should I take CS70 or CS61A?\" \"Should I go to X or X uni, which has a better CS program?\")**, head over to r/csMajors.\n\n&amp;#x200B;\n\nr/CsCareerQuestions: Have a question in regards to jobs/career in the CS job market? Head on over to to r/cscareerquestions. (or r/careerguidance if it's slightly too broad for it)\n\n&amp;#x200B;\n\nr/SuggestALaptop: Just getting into the field or starting uni and don't know what laptop you should buy for programming? Head over to r/SuggestALaptop \n\n&amp;#x200B;\n\nr/CompSci: Have a post that you'd like to share with the community and have a civil discussion that is in relation to the field of computer science (that doesn't break any of the rules), r/CompSci is the right place for you.  \n\n\n&amp;#x200B;\n\nAnd *finally*, **this community will** ***not*** **do your assignments for you.** Asking questions directly relating to your homework or hell, copying and pasting the entire question into the post, will not be allowed.\n\nI'll be working on the redesign since it's been relatively untouched, and that's what most of the traffic these days see. That's about it, if you have any questions, feel free to ask them here!", "score": 516}, {"text": "Is there such a thing as non-asymptotic analysis of algorithms for small n cases?. I am reading lecture notes on a data structures and analysis of algorithms course and I find it interesting but I find two things annoying: \n\n1.  Compiler implementations and hardware specific details and runtimes are omitted.\n\n2.  All run time analysis is asymptotic, even though no computer can run infinitely long.  Nothing in the course worries about real world usage and real world optimization in finite time for everyday usage.\n\nI'm concerned about realistic scenarios like the efficiency in the first hour of use, for example.  I'd rather reduce area under the run time curve at finite times far less than infinity, than worry about what the worst possible case is.  Worst possible case is not good enough for me, I want to also optimize better than worst possible cases I want to optimize in good conditions so that it is even better and perfectly synced up to the hardware it is using.", "score": 126}, {"text": "What are the chances are that quantum computers capable of breaking current cryptography already exists with one or more countries and is kept secret and probably weaponised like the British did during World War 2. During the world war 2, the British team lead by Alan Turing, created Bomba, by improving techniques of polish bombe, to secretly breaking cryptographic messages of the Nazi Enigma machines. They kept it secret and didn't act on the decrypted intel until the D-Day.\n\nThat brings me to this question.\n\nThe information that quantum computing can eventually break all cryptography algorithms that is in use today, is in public domain. Definitely, that is a threat most defence experts are likely working on a priority. So how likely is that one of the defence research group of the world already have it and probably breaking into anything they want?", "score": 314}, {"text": "Similar probabilistic algorithms like Hyperloglog?. Just recently learned about the Hyperloglog and I was wondering if you have any other cool probabilistic algorithms that I should look into. Also, if you have ever used them, I'd love to know in which scenarios.\n\nFor those who doesn't knew HyperLogLog, I wrote very basic notes to myself here  -&gt; https://adriacabeza.github.io/2023/03/15/hyperloglog.html", "score": 113}, {"text": "Lang based on Computability Logic? What might this look like?. ", "score": 51}, {"text": "Google reveals another experimental operating system: KataOS. ", "score": 263}, {"text": "Warning: CSCE - the latest sketchy CS conference by Hamid Arabnia. I'm a CS professor and lately, my academic email account has received multiple Call for Participation emails from \"IEEE CPS - Computer Science, Computer Engineering &amp; Applied Computing\" CSCE'23 conference. My colleagues noted they got the same emails and were wondering about it so I did a little investigating because their CFP looked eerily familiar.\n\n* First warning sign: their website has a banner for the \"American Council on Science and Education\" which is not an established professional organization like ACM or IEEE.\n\n* Second warning sign: the [conference lists 21 different tracks](https://american-cse.org/csce2023/committees) that span the gamut of CS research areas from Bioinformatics &amp; Computational Biology (BIOCOMP) and e-Learning, e-Business, Enterprise Information Systems, &amp; e-Government (EEE) to Foundations of Computer Science (FCS) and Grid, Cloud, &amp; Cluster Computing (GCC). It doesn't have a concentration.\n\n* Third warning sign: it advertises as \"IEEE CPS\" upfront likely to feign credibility. The fact is that **doesn't mean it is sponsored by IEEE**. CPS is IEEE's \"Conference Publication Services\" where they [index papers published by other conferences for a fee](https://ieeecps.org). \n\n* Forth warning sign: \"Professor Hamid R. Arabnia\" is the chair. From what I can find, he's actually retired. If you're unfamiliar with him, he has gained a notorious reputation for running fraudulent conferences with these same red flags. He used to run [WORLDCOMP which got roasted in this subreddit 11 years ago](https://www.reddit.com/r/compsci/comments/qmf46/worldcomp_the_worlds_biggest_sham_computer/) and a sock puppet account even replied in that thread to defend it with [a copy-and-paste post it had in another one of its four total posts -- all alleging a conspiracy to defame him](https://www.reddit.com/user/truth10000/). Alarms were also raised [5 years ago when he rebranded it as \"CSCI\"](https://www.reddit.com/r/computerscience/comments/84pdzz/worldcomp_or_csci_are_fake/). In fact, the old WORLDCOMP website [world-academy-of-science.org](http://www.world-academy-of-science.org/) currently redirects to the latest renaming of the conference, \"CSCE\" at [american-cse.org](https://american-cse.org).\n\nAllegations about these conferences (including on the previous reddit threads as well as [elsewhere](https://www.ripe.net/ripe/mail/archives/dns-wg/2013-December/002831.html)) are that there is no real peer review happening and it is a predatory conference that just accepts anything and cashes in on registration fees. Many legitimate researchers have complained that they were duped by the conference and when they attended it (always in Las Vegas, as far as I can tell), there were some real research presentations but it was obvious that there was no meaningful peer review being conducted to assure that the research was sound.\n\n*update* - after filtering \"@american-cse.org\" as spam, I'm now getting daily emails for the same CFP from \"@world-comp.org\" addresses.", "score": 248}, {"text": "The Implementation of the Coordinate Hash Trie. ", "score": 84}, {"text": "A Trie Variant Balancing between Time, Space, and Simplicity; And a C Implementation of the Aho-Corasick Algorithm Based on It. I think this sub is a suitable place to share my work.\n\n* Implementation of the trie variant: &lt;https://github.com/dongyx/chtrie&gt;\n* Paper of the analysis and proof: [https://arxiv.org/abs/2302.03690](https://arxiv.org/abs/2302.03690)\n* Application in the A.-C. algorithm: [https://github.com/dongyx/libaca](https://github.com/dongyx/libaca)\n\nThe approach is called *coordinate hash trie*.\n\nThe idea is very simple.\nWe use a global hash table to store all edges in a Trie. Each edge is stored as a dictionary item `(from, symb)-&gt;to`.\n\nWe use a special hash function:\n\n    h(from, symb) = (from*m + symb) mod H\n\n, where `m` is the size of the alphabet, and `H` is the number of slots in the hash table. For a trie with `n` states(nodes), we take `H = (n-1)/alpha` where `alpha` is the constant load factor. **No rehashing, resizing, or reallocation is required.**\n\nWe could prove that **the time complexity of transition from one state to another, is O(1) for the average case and O(m) for the worst case**. **The space complexity is O(n), unrelated to** `m`.\n\nComparing to other compressed trie variants like *double array trie*, or using `n` hash tables each for a state, this variant provides stable space consumption and is very easy to implement.", "score": 107}, {"text": "Cache Oblivious Algorithms. ", "score": 123}, {"text": "Gradient Boosting with Regression Trees. Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/lOwsMpdjxog) where I explain what gradient boosting is and how it works.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)", "score": 59}, {"text": "Techniques for Scaling Applications with a Database. ", "score": 21}, {"text": "MINIX is an awesome way to learn a wide range of CS concepts. ", "score": 191}, {"text": "Man beats machine at Go in human victory over AI. ", "score": 519}, {"text": "Odd Sketches. ", "score": 11}, {"text": "Dijkstra Comparing Computer Science to Alchemy (1989). ", "score": 261}, {"text": "Voting Preference Sorting a list. A list of eight items to be sorted s = {a, b, c, ... h}. Fifty voters each contribute their ordering preferences in the form of a three-item priority list: preferences = {first, second, third}\n\n**What method sorts the eight items according to the set of fifty 3-item preferences**, without the introduction of any sort of arbitrary weighting?\n\n*What have I tried:*\n\n* A 3-dimensional count seems to leave me with three lists of counts, one for first, second, and third preference. That problem space looks to me like a partial set of permutations.\n* Start with only one vote, which leads to a count of votes per item in the set. What happens when instead I specify a preference for the ordering of two items? Which looks to me a like a relationship between nodes, rather than just the nodes.", "score": 3}, {"text": "Mathematicians Complete Quest to Build \u2018Spherical Cubes\u2019 | Quanta Magazine | s it possible to fill space \u201ccubically\u201d with shapes that act like spheres? A proof at the intersection of geometry and theoretical computer science says yes.. ", "score": 181}, {"text": "Starting now: Reading group for \"The Joy of Abstraction\" by Eugenia Cheng. ", "score": 28}, {"text": "How do I traverse every point in a 3D area without backtracking and minimizing the least amount of turns possible?. Alright, let's say I have an array of discrete 3D points that make a rectangle of x, y, and z length. I want to visit every point in the least amount of turns possible without backtracking. Let's say that to visit a point you can only increase x, y, and z by +-1 or 0. The pattern ends up being a snake-like pattern where the axis is traversed in descending order to minimize the number of turns. Though getting this to happen in code eloquently has been a real fucking bitch. \n\nSo far, I've generated the area with no care in which order they're put in. Then I sort so the longest axis is moved through first, then I go through once and create subsets for every time two axis values have been changed (xChange &amp;&amp; yChange) || (xChange &amp;&amp; zChange) || (yChange &amp;&amp; zChange) and add every one of those elements back to a new list where every other subset is in reverse order. Then I do that again but create a subset this time when every axis value has been changed (xChange &amp;&amp; yChange &amp;&amp; zChange). This cant be a novel problem, right? I can't find anything online about this.\n\nExample input: https://pastebin.com/JbXx19rf\nExample output: https://pastebin.com/sWsfXq3G", "score": 7}, {"text": "The story behind the Packing Chromatic Number paper. ", "score": 78}, {"text": "Normalization for multimodal type theory. \"We prove normalization for MTT, a general multimodal dependent type theory capable of expressing modal type theories for guarded recursion, internalized parametricity, and various other prototypical modal situations.\" [abstract + link to PDF, 39pp]. ", "score": 111}, {"text": "Don't fear the spin lock. It's a common exercise in programming to synchronize access to data between threads. A simple mutex or other critical section tool will do the job. But sometimes, performance matters.\n\nThe problem with mutex's, or regular locks in high level languages, is that the waiting thread may be put to sleep since it cannot access the resource it wants.  And this behavior is usually desirable - except when it isn't.\n\nThere is a time cost associated with putting the waiting thread(s) to sleep and waking them when the resource is ready.\n\nA simple heuristic can be used to determine whether you should try to upgrade regular wait locks to spin locks. A spin lock is where the thread actively tries to access the shared resource and doesn't go to sleep.\n\n(h): if the shared resource is guaranteed to be locked for a sufficiently short period of time.\n\nWhile working in [Orvina](https://github.com/webbersmak/Orvina), performance increased dramatically with a careful selection of locks to upgrade to spin locks - and the effort was less trouble than what was expected.\n\nThere are likely many programs out in the wild that would experience real world benefits with more diligence in the choice of locking mechanism implemented. It would be quite the feat if compilers could deduce or suggest a specific lock type and insert the correct one. Perhaps that's one improvement AI will contribute to.\n\nhttps://preview.redd.it/c9t2dpu1ctea1.jpg?width=768&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ef75d8d723f8a9ed6c025f5047e644b99c92ccd6", "score": 60}, {"text": "Diagram layout engines: Minimizing hierarchical edge crossings. ", "score": 124}, {"text": "What is a zip tree, and how does it work?. ", "score": 175}, {"text": "What sparked everyone\u2019s interest in CS?. Aside from enjoying video games and having to choose something for a-levels (my case), what could spark an interest in computer science? I really want to hear everyone\u2019s personal experiences and opinions.", "score": 58}, {"text": "KHyperLogLog. ", "score": 65}, {"text": "Are there any machines that are powerful than Turing machines or has violated the Church-Turing hypothesis?. Basically the title.", "score": 15}, {"text": "Why Neural Nets Underperform Tree-Based Models on Tabular Data. Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/e62CBva4TYc) where I discuss about why deep neural networks fail to beat tree-based models on tabular datasets.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)", "score": 73}, {"text": "how to benchmark a programming language. I am working on building a programming language. The interpreter is written in Go.\n\nIs there a way to benchmark programs written in that language vs the same program written in other programming language. For example a fibonacci program written in that language vs a fibonacci program written in Python", "score": 69}, {"text": "Infinite Tetris is Turing-complete. ", "score": 227}, {"text": "Bio-Inspired Optical flow. ", "score": 64}, {"text": "Finally, a Fast Algorithm for Shortest Paths on Negative Graphs. ", "score": 282}, {"text": "You should be reading academic computer science papers. ", "score": 342}, {"text": "Recursive Types via Domain Theory // The Topos Lab. ", "score": 48}, {"text": "ACM: The End of Programming. ", "score": 99}, {"text": "GETCO 2022 / Uli Fahrenberg / Directed Topology and Concurrency. ", "score": 18}, {"text": "Summer Geometry Initiative 2023 --- undergrad/MS summer research in geometry processing! Applications due 2/15/2023. ", "score": 39}, {"text": "How to Use K-means for Big Data Clustering?. ", "score": 32}, {"text": "The Incredible World of Quantum Mechanics - How it is Used in Modern Quantum Computing. Quantum mechanics is a field of quantum physics that studies the behavior and interactions between atoms and molecules. It's an incredibly complex topic, but it can be broken down into some basic concepts. The idea behind quantum mechanics is that even though we cannot see or touch them, there are tiny particles all around us! These particles behave in strange ways that break from our everyday experience with matter. Quantum computing is a relatively new way to use these particle waves to do calculations much more quickly than traditional computers can do today. In this post, I'll introduce the most basic concepts of quantum mechanics and explain why it's important for understanding quantum computing! \n\nGet started here: \n\n[https://deepboltzer.codes/the-incredible-world-of-quantum-mechanics](https://deepboltzer.codes/the-incredible-world-of-quantum-mechanics)", "score": 122}, {"text": "The Biggest Discoveries in Computer Science in 2022. ", "score": 159}, {"text": "A report on the Collatz problem. As of January 6, 2023, the project [Convergence verification of the Collatz problem](https://pcbarina.fit.vutbr.cz/) was able to verify the validity of the Collatz conjecture for all numbers less than 660 \u00d7 2^(60) (\u2248 2^(69.37)). The project started its operations on September 4, 2019. On May 7, 2020, it verified the convergence of all numbers below 2^(68), while on December 10, 2021, it verified all numbers up to 2^(69). The project consumed 5395 CPU-years of computing time (of which 5308 years using the CPU and 87 years using the GPU). The project uses work units of 2^(40) numbers. Verifying one such unit takes, on average, 5:25 minutes on the CPU and 12 seconds on the GPU.", "score": 114}, {"text": "2022 Top AI Papers \u2014 A Year of Generative Models. ", "score": 150}, {"text": "I created a tool to visualize/edit graphs and graphs algorithms. I created a tool to create/edit a graph and to visualize graph algorithms (like Dijkstra,kruskal etc).\n\nThe project was made entirely using js (p5js,ts).\n\nI think the most interesting part about this project is the fact that you can change the graph (delete edge, move a vertex, set the graph to be weighted or directed etc etc) and the algorithm visualization changes in real time. Give it a try and i'd love to hear some feedback :D\n\ndemo: [https://giggiox.github.io/graphTheory-Visualizer/](https://giggiox.github.io/graphTheory-Visualizer/) (better on pc {zoom using mouse wheel})\n\ncode: [https://github.com/giggiox/graphTheory-Visualizer](https://github.com/giggiox/graphTheory-Visualizer)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/958snc48mw8a1.png?width=1366&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b9248b701e07914004627b12b629ee2b97e90ca3", "score": 139}, {"text": "Formal definitions of \"events\" and \"messages\" in distributed systems?. I'm studying up on version vectors &amp; vector clocks, but I'm held back on my fuzzy understanding of what an \"event\" actually is. From [Lamport '78](http://lamport.azurewebsites.net/pubs/time-clocks.pdf) :\n\n&gt; We assume that sending or receiving a message is an\nevent in a process.\n\nBut he never really defines what a message is, except to say \n\n&gt; A distributed system consists of a collection of distinct\nprocesses which are spatially separated, and which communicate with one another by exchanging **messages**.\n\nMaybe I'm missing the forest for the trees here, but I feel like my intuitive understanding of what an event is or isn't is not enough.", "score": 56}, {"text": "Von Neumann was admonishing people who built assemblers (Snapshot from a book called The History of Fortran). ", "score": 489}, {"text": "Technically and functionally speaking, are folders in filesystems relevant?. Hello everyone!\n\nI hope I'm posting a good question in the right subreddit and I'm not violating any rules.\n\nSo, as the title is: Are folders relevant? I know it's tidy, easier, and makes life easier and safer. But are folders really essential for a computer to function? In an abstract sense, not necessarily on current filesystems/OSes. I googled a bit and all the answers I'm getting on how useful folders are, but not whether we can do away with folders or not for a computer to run even if it means having to create a new filesystem/OS.\n\nI know we can set permissions on folders especially when we want to share them across networks, but we can potentially do the same on files levels and set some sort of flags on metadata for permissions and such. Maybe names could be a problem, but we can refer to files by some GUID or something and include the name in its metadata (And probably version too).\n\nI personally dump most of my files in a single folder and look files up by name, type, size, date and get to needed files almost all the times without hiccups.\n\nWhat do you think, are folders really important for a computer to run in terms of functionalities and technicalities? What would not having folders structure implies?", "score": 0}, {"text": "Proximal Policy Optimization - Dive into the Unknown. Proximal Policy Optimization (PPO) is a policy search algorithm and an on-policy reinforcement learning algorithm. PPO algorithm aims to optimize the expected reward of a given policy by adjusting the parameters of that policy in order to maximize its probability of success. This makes it easy to deploy in real-world applications since it does not rely on complicated off-policy techniques, but instead on simple updates to the policy. In addition, it has been shown to be highly sample efficient, making it a good choice for applications with limited data and resources. PPO also provides better exploration than most other reinforcement learning algorithms, which ensures rapid convergence of policies in complex environments. Finally, PPO is well-suited to continuous action spaces and has been used in robotics applications. In this post we will explore the PPO algorithm in detail and dive into the unknown! So join us learning PPO together and discover how this great reinforcement learning algorithm can help you reach the best performance possible. \n\n[https://deepboltzer.codes/proximal-policy-optimization](https://deepboltzer.codes/proximal-policy-optimization)\n\nHappy Learning!", "score": 34}, {"text": "Understanding the core concepts of Policy Gradient Methods.  Let us understand the core concepts underlying various\u00a0policy gradient algorithms! In simple terms, policy gradient methods are a type of reinforcement learning algorithm which allows us to learn the optimal parameters of a given environment in order to maximize rewards.\u00a0As opposed to previously introduced methods - which suffered from the curse of dimensionality - it is not necessary to analyze the full action space to update the policy\u00a0\u03c0. Instead of learning the parameters of a policy directly, the algorithm learns the gradient of expected rewards with respect to those parameters. The idea is that by taking small steps in the direction suggested by this gradient, we can converge on optimal policy parameters. So if you want to learn more about how policy gradient methods work, feel free to explore our latest blog post. We hope that this will help to get a better understanding of policy gradient methods! If you still have any questions or would like to discuss further, do not hesitate to reach out - we are always happy to help.\n\n[https://deepboltzer.codes/introduction-to-policy-gradients](https://deepboltzer.codes/introduction-to-policy-gradients)\n\nHappy learning!", "score": 33}, {"text": "To what extent can a proof assistant like Lean verify its own correctness?. I've been using the [proof assistant Lean](https://leanprover.github.io/about/) a bit recently, and it got me thinking about whether I can prove Lean to be correct or not.\n\nImagine that I wanted to prove the statement *P* = \"Lean will accept a proof as correct if and only if that proof is correct.\" Is it actually possible to prove *P*? If so, is it possible to formalize that proof in Lean?\n\nEven if we could formalize *P* in Lean and Lean accepted it as a valid proof, would that even be enough to verify Lean's correctness? After all, if Lean (incorrectly) accepted *any* theorem as true, wouldn't it accept *P* even if *P* was false?", "score": 61}, {"text": "Is there any decision making/predicting algorithm that can give a decision/prediction that can give a 100% probability of it being good/true?. ", "score": 0}, {"text": "Consistent hashing explained. ", "score": 61}, {"text": "Found this while reading SICP from MIT.. ", "score": 700}, {"text": "Does google have exclusive right to scrape the internet? And can they scrape everything?. Does Google have the exclusive rights to scrape the internet? I could imagine that people exist, who have a website and thinking to themselves that they don\u2018t remember giving google the rights to show their website and the content of their website.", "score": 0}, {"text": "What is your view on the Halting Problem of Turing Machines and how do you propose to solve it?. ", "score": 0}, {"text": "Proofs about programs - an interactive tutorial I wrote. ", "score": 200}, {"text": "Resources to understand compressed sensing?. I'm reading a paper about compressed sensing and I was somewhat lost on the concept. Are there any good resources (e.g. videos, books, papers) I can use to gain some insight? Thanks!", "score": 48}, {"text": "If the day comes that quantum computers are commercially available, would it be possible to buy one and use it to crack my locked android phone's encryption?. So on my old Huawei phone I have alot of pictures from when I visited the US the summer of 2019. Nowadays I remember that trip as the best time of my life, but because my brain did a dumb I can't remember the 6-digit PIN to the phone and so all the photos are inaccesible. And no, they're not backed up anywhere :/. But I read somewhere that quantum computers will theoretically be able to crack AES-128 encryption, which is what I'm told android phones are using.\n\nSo my question is will this actually be practically possible, or is there perhaps some other caviot that I don't know about?\n\nOh and I don't know if it makes a difference but I haven't used up all my PIN chances so the phone isn't \"permanently\" locked yet.", "score": 0}, {"text": "Competition-Level Code Generation with AlphaCode. Deepmind proposed AlphaCode, a system for code generation that can create novel solutions to these problems that require deeper reasoning. In your opinion, what can we learn from it. What are the short- and long-term consequences?", "score": 0}, {"text": "RSS Feed Integration using Node.js(Express). ", "score": 0}, {"text": "How would you write an algorithm to solve this?. ", "score": 1017}, {"text": "What is the use to data structures if we save and retrieve all the data in databases.. ", "score": 0}, {"text": "Is there always a non-amortized version of every data structure that matches the best amortized one?. Often some operations on a data structure run in O(1) or O(log n) amortized time. However, I don't recall any such data structures without an equivalent one which supports the same operations with the same complexity without relying on amortization. Usually, the latter DS is much more convoluted and impractical, but that is irrelevant here.\n\nI now started wondering whether there is a known result about this. Either there is an equivalent non-amortized DS for every amortized DS, or there is some amortized DS with no such equivalent. Perhaps there is no proof either way, but maybe there is some amortized DS with no known non-amortized equivalent. Does anyone know?", "score": 43}, {"text": "We need search capability over AI-generated content. The availability of language models such as GPT-3 (and the recent chat version #chatGPT) can be as disruptive as the search engines were in the past. New tools are good, in the sense that they can expand our productivity, but there can be some downsides. We have learned that not all we read on the internet is true, and the same goes for AI-generated content. This content can often be true, but it is produced to look plausible. Truth is often just an accident. \n\nOne thing is true,  AI-generated content is very credible at first glance and hard to distinguish from human-generated content. Recently [Stack Overflow banned AI-generated content](https://www.theverge.com/2022/12/5/23493932/chatgpt-ai-generated-answers-temporarily-banned-stack-overflow-llms-dangers).  But how can we detect such content in an efficient way?\n\nProbably the simplest solution is for the hosts of the language models, such as OpenAI, to store the outputs and provide search capability over past outputs.", "score": 136}, {"text": "What happens when you type a URL into your browser?. ", "score": 0}, {"text": "URL Shortening System Design. ", "score": 97}, {"text": "Slitherlink / Fences / Takegaki / Ouroboros puzzle generator. This game goes by many names but it's [this one](https://en.wikipedia.org/wiki/Slitherlink). I'm working on an implementation and I'm thinking that first and foremost, I should create the puzzle generator.\n\nI'm thinking of utilizing a modified tree generation algorithm (perhaps Prim's?). Where some cells behave like \"walls\" in a typical maze.\n\nMy main question is... what do you think is the best data structure for this? I need to be able to check for cycles quickly. And I need to be able to associate each cell with the edges on its boundary.\n\nI was thinking of perhaps just using a naive nxm 2D array for the cells, generating a \"maze\" on top of them, populating every cell with its \"clue value\" and then removing clues until the game is barely solvable.\n\nIn terms of gameplay, I was thinking I would maintain an array of arrays of the form `[[starting_i, starting_j], ...oneOfFourUnitVectors]` (which I call \"chains\", with each unit vector being a \"link\"). So this would be an array of all unconnected \"chains\".\n\nThoughts?", "score": 7}, {"text": "Advent(2) -- The System-Call Advent Calender. Winter is coming and the ELFs have a lot of work to do in Santa's Christmas village. And the ELFs, as the name suggests, are big fans of Linux to get this work done in time. However, until now they only know about those old a crusty interfaces that we inherited from UNIX/POSIX. So, they require your help! On the way, you can learn something about old and new system calls of Linux.\n\n[https://osg.tuhh.de/Advent/](https://osg.tuhh.de/Advent/)\n\nThe Operating System Group at the Hamburg University of Technology prepared a System-Call Advent calendar with 24 strace-filled doors for you. On every day of December, you will find a system-call, a concept or an interface of Linux that you might or might not yet know. Behind the door, there is a short article and a small programming exercise, for which we provide a commented solution on the following day.", "score": 63}, {"text": "How Bios is able to display GUI. Without any OS or drivers how the bios is able to display a TUI or a full GUI(UEFI)", "score": 27}, {"text": "ICPC Archives: Collection of problems and solutions of final and regional ICPC contests. ", "score": 19}, {"text": "how to solve an alien problem you can't comprehend?. Like for example if I give you a 10x10 Rubik's, you have never  solved, even a 3x3 Rubik's cube before. How would you approach it?", "score": 48}, {"text": "Is Computer Science Theory application expandable to real world application?. I'm currently a Junior in CS and am taking the Computer Science Theory (CSCI338) course wherein they are teaching us about DFA's, NFA's, TM's, P, NP, NP-C, etc. and the coding assignments that were given to us seem less usable in real world applications than what I can come up with is there something that I'm not seeing with these projects?\n\nProject 1: State diagram \"game\", have a pseudo character with these states and an action would change your state, like a DFA. (I feel like this could work in game dev but it seems a little primitive)\n\nProject 2: NFA generator, using a hashmap of a hashset we give the program a string of 0's and 1's with concatenations, union, star, and plus, to generate an NFA, then give it test strings to see whether they will be accepted in the NFA generated.\n\nProject 3: Creating 4 algorithms, inexact vertex cover, exact vertex cover, inexact independent set, and exact independent set, and for the algorithms of the inexact the nontrivial recommend solution was taking the set to test and removing one index testing if that set is a vertex cover and if it is then it will add the array index in then move to the next index (independent set is complement of vertex cover so similar logic applies to the inexact IS) which would work in O(n\\^2), and for the exact we would generate the powerset of the set given and test each set as a vertex cover and it works in O(n\\*2\\^n) and isn't largely usable above 20 or 30 nodes (30 nodes takes about \\~8 minutes). I asked the professor about what is usable from this project and he said the power set would probably be the only thing that is used for larger scale application.\n\nThe class is theoretical computer science so I guess these projects would deal with just proving the proofs in class but I'm wondering if any skills developed in these projects would help in real world application development?", "score": 0}, {"text": "Computer History Museum releases Adobe Postscript source code today!. Hey Everyone,\n\nHuzzah!\n\nAs promised, today the Computer History Museum is releasing the original Adobe Postscript source code. \n\nRead our introductory blog on the history of this cool technology and pick up your sources here:\n\n[https://computerhistory.org/blog/postscript-a-digital-printing-press/](https://computerhistory.org/blog/postscript-a-digital-printing-press/)\n\nThis release is part of the Museum\u2019s Art of Code program, which you can sing up to hear more about and get updates on code releases here: [https://info.computerhistory.org/subscribe-aoc](https://info.computerhistory.org/subscribe-aoc)\n\nFor background on our Art of Code program, be sure to read our Art of Code blog here: [https://computerhistory.org/blog/the-art-of-code-at-chm/](https://computerhistory.org/blog/the-art-of-code-at-chm/)\n\nComing soon\u2026\n\nApple Lisa source code \u2013 release date: January, 2023\n\nXerox PARC Alto source code: release date: March, 2023\n\nThe Computer History Museum is home to the world\u2019s largest collection of computer hardware, software, media, documentation and ephemera and everything we offer is free, but doing so is not without cost. If you\u2019d like to support our efforts \u2013 even a small token amount sends us a signal you think we\u2019re doing good work \u2013 have a look here: [https://chm.secure.nonprofitsoapbox.com/donate](https://chm.secure.nonprofitsoapbox.com/donate)\n\nWould love to hear your feedback \u2013 publicly, or personally at my email below.\n\nThanks everyone \u2013 this is going to be a great year for software history!\n\n\\-- Dag.\n\nDag Spicer  \nSenior Curator  \nComputer History Museum  \nE-m: [spicer@computerhistory.org](mailto:spicer@computerhistory.org)", "score": 117}, {"text": "Question about Predicate Transformer Semantics. I'm trying to learn a little bit about Predicate Transformer Semantics (PTS) as part of a quick exploration of [Z3](https://github.com/Z3Prover/z3).\n\nI'm reading the [wikipedia's article](https://en.wikipedia.org/wiki/Predicate_transformer_semantics) about PTS and I have some doubt about the [first wlp](https://en.wikipedia.org/wiki/Predicate_transformer_semantics#Partial_Correctness) for the *while loop*, i.e. the one ignoring termination.\n\nFirst, I would replace the *if* in the formula with an *and* as I don't think the formula is syntactically correct the way it's written.\n\nSecond \u2014 this is my main doubt \u2014 I don't understand how we can be sure that the precondition, P,  given by that formula is still valid when we loop many times. Let's consider the forward direction: P makes sure that the INVariant is true, and that if the loop condition is true then, after we perform one iteration, the INVariant is still true. But how can we be sure that P is still valid for the next eventual iteration, though?\n\nI also found a [more hands-on article](https://www.philipzucker.com/weakest-precondition-z3py/) about PTS. The author relies on Z3 and defines the statements as functions which return the associated wp functions. For instance, `if_(b&lt;a, stmt1, stmt2)` returns the function `lambda post_cond: wp(if b&lt;a then stmt1 else stmt2 end, post_cond)`. This way, by combining these statements, we can build the wp function for a whole algorithm. For instance:\n\n    def twosort(a,b):\n        if b &lt; a:\n            temp = a\n            a = b\n            b = temp\n        else:\n            pass\n        return a,b\n\nbecomes\n\n    a, b, temp = Ints(\"a b temp\")\n    prog = \\\n    if_(b &lt; a,\n        begin(\n             set_(temp,a),\n             set_(a, b),\n             set_(b, temp)\n             ),\n        skip\n       )\n\nHere's the important bit. The author implements the while loop as follows:\n\n    def while_(cond, inv, *body):\n        def res(post):\n            vs = list(get_vars(post))\n            return And( inv , \n            ForAll(vs, And( Implies( And(cond, inv), begin(*body)(inv))\n                            , Implies( And(Not(cond), inv), post) )))\n        return res\n\nThis seems to agree with wikipedia's formulation except for that `ForAll`. I suspect the reason we might need that `ForAll` is connected with my doubt... or maybe not?\n\n**edit**: added link to hands-on article!", "score": 7}, {"text": "Good sites to learn how to ethically hack..for free (?). The reason I say free is because I am a student with no financial income yet. Any courses that let you learn then pay for a certificate at the end are also fine, I just want a place to learn for free", "score": 5}, {"text": "The Legacy of Peer-to-Peer Systems. What happened to peer-to-peer as a technological concept? Actually, we still use a lot of that technology. Fresh blog post on this dive into the past [https://cacm.acm.org/blogs/blog-cacm/267236-the-legacy-of-peer-to-peer-systems/fulltext](https://cacm.acm.org/blogs/blog-cacm/267236-the-legacy-of-peer-to-peer-systems/fulltext)", "score": 4}, {"text": "Is the Von-Neumann architecture used on GPUs?. I\u2019m sorry for my being illiterate on the topic. I\u2019ve studied computer architectures before, and I was wondering first of all how do GPUs fit into the Von-Neumann template, and what do GPUs have. I know they use different names such as Maxwell, Ampere etc. for Nvidia, but are they actually different variations of Von-Neumann or completely different things? Thanks for your time :)", "score": 115}, {"text": "Researchers found that accelerometer data from smartphones can reveal people's location, passwords, body features, age, gender, level of intoxication, driving style, and be used to reconstruct words spoken next to the device.. ", "score": 834}, {"text": "How's multiplication is not an np problem? what a billion digit number is being multiplied with another billion digit number? Can it be solved in polynomial time?. ", "score": 0}, {"text": "Scientists Increasingly Can\u2019t Explain How AI Works. ", "score": 0}, {"text": "Multivariate Normal Distribution Explained. Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/UVvuwv-ne1I) where I explain what the multivariate normal distribution is, together with the meaning behind the equation that describes its behavior.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)", "score": 6}, {"text": "Why Functional Programming Should Be the Future of Software Development. ", "score": 2}, {"text": "Temporal Programming, a new name for an old paradigm. ", "score": 8}, {"text": "Easy to understand Blockchain Beginner Books [ Recommendation ]. Hi there, I want to learn blockchain. I am a complete newbie. All I know so far is that it's decentralized no single entity or organization is the owner of the data/stuff. Please let me know what book is easy to follow in the beginning in this field.", "score": 0}, {"text": "Cache invalidation really is one of the hardest problems in computer science. ", "score": 277}, {"text": "Online Portfolio Selection - Cover's Universal Portfolio. Hi r/compsci\n\nMy 2nd blog on online portfolios is about Cover's Universal Portfolio algorithm. [https://sudeepraja.github.io/OPS2/](https://sudeepraja.github.io/OPS2/)\n\nTheoretically, it has the best performance. But it is computationally expensive to implement. I give two different interpretations of this algorithm. One is based on Follow the regularized leader and the other is a kind of Bayesian update.\n\nI implement it for the case of two stocks. Guess what happens when you use it for a leveraged ETF and its inverse like TQQQ, SQQQ - &gt;!You lose money anyway.!&lt;\n\nMy first blog on this topic is here: [https://sudeepraja.github.io/OPS1/](https://sudeepraja.github.io/OPS1/)", "score": 1}, {"text": "Online Portfolio Selection - Introduction. Hi r/compsci\n\nI spent the last two years reading about online portfolios from a theoretical and practical standpoint. In a series of blogs, I intend to write about this problem. For me, this was a gateway into online algorithms, portfolio optimization, and quantitative finance. I also included code snippets to play around with. [https://sudeepraja.github.io/OPS1/](https://sudeepraja.github.io/OPS1/)\n\nI appreciate all corrections and feedback.", "score": 38}, {"text": "Computer History Museum to release historical source code. Hi all!\n\nI\u2019m a curator at the Computer History Museum and we\u2019re making some epic source code releases in the next few months:\n\nAdobe Postscript source code \u2013 release date: Dec 2022\n\nApple Lisa source code \u2013 release date: January, 2023\n\nXerox PARC Alto source code: release date: March, 2023\n\nThis is part of the Museum\u2019s Art of Code program, sign up to receive updates on code releases here: [https://info.computerhistory.org/subscribe-aoc](https://info.computerhistory.org/subscribe-aoc)\n\nFor background on our Art of Code program, be sure to read our Art of Code blog here: [https://computerhistory.org/blog/the-art-of-code-at-chm/](https://computerhistory.org/blog/the-art-of-code-at-chm/)\n\nCHM is home to the world\u2019s largest collection of computer hardware, software, media, documentation and ephemera and everything we offer is free, but it is not without cost. If you\u2019d like to support our efforts \u2013 even a small token amount sends us a signal you think we\u2019re doing good work \u2013 have a look here: [https://chm.secure.nonprofitsoapbox.com/donate](https://chm.secure.nonprofitsoapbox.com/donate)\n\nThanks everyone \u2013 this is going to be a great year for software history!\n\n\\-- Dag.\n\nDag Spicer\n\nSenior Curator\n\nComputer History Museum\n\nE-m: [spicer@computerhistory.org](mailto:spicer@computehistory.org)", "score": 541}, {"text": "Can a new form of cryptography solve the internet\u2019s privacy problem?. ", "score": 10}, {"text": "Makeshift GPU tensor core using 64-bit CPU integer math. ", "score": 12}, {"text": "Hash Treap: The simplest balanced binary tree, easy to program, no recursion, and no extra data in each node. ", "score": 10}, {"text": "Why Neural Networks Can Approximate Any Function (The Universal Approximation Theorem). Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/O45AaRPQhuI) where I explain why neural networks are considered universal function approximators.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)", "score": 207}, {"text": "Linked lists and trees(help). I'm a 2nd yr computer scince student and I'm currently struggling with linked lists and trees, the lectures don't seem to help, does anyone know any good youtubers that are good at explaining the programming side of these concepts?", "score": 0}, {"text": "Where next for program synthesis?. Hi all, first of all I don't have an academic CS background so please forgive me if I am not up to date on the latest research. I am interested in program synthesis and where it is going, but lots of the debates I see online (HN etc) seem to descend into the usual GOFAI vs. ML fights and I lack the background to determine what seems credible.\n\nMy understanding is that until recently program synthesis focused on generating correct programs from example test cases by search or maybe ILP etc. To be honest, it seems that this didn't get very far. I have seen references to Flash Fill in Excel but I am not aware of anything else with large scale adoption or that can generate more that small algorithms (is this incorrect?).\n\nRecently, systems such as Copilot use ML to generate likely code from prompts. The problem is that the model doesn't 'really understand' the output code and often it is incorrect or doesn't compile. Still, Copilot seems to have provided utility. On the other hand, GOFAI proponents might say that Copilot doesn't even know how to output correct code.\n\nI have read ML proponents argue that more data and better models usually lead to a more capable system. For example, I believe GPT-3 can do arithmetic that GPT-2 couldn't do. However, Copilot has already been trained on all of Github's public code. Where would further data come from? I am aware that places like Salesforce have been using RL with test cases to improve results, but even so they are only getting 40% correct with 1000 attempts. Will better model architectures alone lead to much better results?", "score": 40}, {"text": "Found this, easily explained and informative. [https://youtu.be/2cGtLD1r4bg](https://youtu.be/2cGtLD1r4bg)", "score": 0}, {"text": "Please recommended any good course on Blockchain development. I'm studying JavaScript right now because I have an interest in blockchain development. Anyone who has taken courses in blockchain development can help me out because I previously searched this question but am now totally confused.", "score": 0}, {"text": "SECDED Hamming Codes: Daniel Bernstein's libsecded and an alternative algorithm that does not modify the data. ", "score": 22}, {"text": "Data Origin Authentication vs Non Repudiation?. Hey all\n\nI'm looking into how authenticated encryption primitives work and was wondering if non-repudiation is provided with these. Investigating further into them led to the answer being that **data origin authentication** (DAO) are provided by the primitives.\n\nNow DAO is defined as \"the source of the information being verified\", providing integrity through MAC. Yet Non-repudiation is almost defined as the same thing, in which it provides proof of the origin and the creator of said data being **unable to deny** that they created the data.  \n\nIf they both say the same thing, then why is it that some sources state that authenticated primitives do not in fact have non-repudiation when they do? Some say that the seperate primitives that **are combined** result in non-repudiation being created, but I am so genuinely confused at what I'm supposed to take from this.", "score": 46}, {"text": "Negative-Weight Single-Source Shortest Paths in Near-linear Time. ", "score": 138}, {"text": "New data transmission record set using a single laser and a single optical chip. ", "score": 56}, {"text": "Bor\u016fvka's algorithm. ", "score": 91}, {"text": "15-816 Substructural Logics - Pfenning -- 2016. ", "score": 50}, {"text": "Feature of Artificial Intelligence. ", "score": 0}, {"text": "How does Shor's algorithm break ECDSA?. Hey all\n\nSo I was currently working on some piece of work related to Elliptical Curve Cryptography and Quantum computers and found a question asking if quantum computing could break ECDSA.\n\nShor's algorithm, from what I have researched, works by the probabilistic nature of qubits which drastically reduce the time taken for factorisation.\n\nBut maybe it is because that I do not understand how Elliptical curves work because I don't know how that relates into breaking through ECDSA, and I'm just perplexed at this point. Would appreciate an explanation as to how this all works.", "score": 39}, {"text": "Where am I wrong (reading the paper about NFA unambiguity check). I'm reading an article \"An O(n^2) time algorithm for deciding whether a regular language is a code\" by Robert McCloskey. Everything is very simple and clear, it seems to me, that there is much more straightforward approach for this purpose, which provide more general result. It's so simple, that it seems like I'm wrong somewhere:\n\nSuppose we have a set of regular expression. Construct an NFA in the following way:\n\nFor each expression build an NFA, such that for each acceptable string there is only one path from the initial state to any of terminal states in it. Then build one cyclic NFA as a disjunction of those, i. e. from new initial state add eps-moves to all initial states of previously constructed NFAs and from all terminal states of previously constructed NFAs add an eps-move to initial state. Make initial state of this complex NFA to the only terminal state of it.\n\nAs far as I understand, this NFA corresponds to the language, consisting of the words, that can be split into the strings accepted by some of the regular expressions, i. e. exactly the language, described in the article. Moreover, disambiguation problem can be reformulated in terms of this NFA in a very simple manner: we want to know, if there exist two different paths from initial state to terminal (i. e. to itself), spelling out the same word. And the latter problem can be easily solved using the same kind of a direct product of an NFA, described in the paper (we should check if there are paths from (init, init) to itself in the graph from p. 7, that go through at least one non-diagonal node).\n\nYes, algorithm from the article is also not too hard, but this one is even simpler. Therefore, it seems to me, that I have missed something important. I'd be very grateful for any idea of what can go wrong here", "score": 24}, {"text": "Programming and Order Theory. ", "score": 88}, {"text": "Is \u201cx' = f(x)\u201d a programming paradigm?. ", "score": 89}, {"text": "Algorithm that runs faster on big input but runs slower on smaller input. In computer science, we know that there are several algorithms that performs faster on smaller inputs but performs slower on large inputs (O(logn), O(n) and so on)\n\nI have two fairly basic questions:\n\n1. Is there any algorithm which performs poorly on a smaller input but runs faster on a large inputs?\n\n2. How do we measure asymptotic complexity of such algorithm?", "score": 166}, {"text": "Evolving a rigid body to throw another one the farthest with UI. ", "score": 395}, {"text": "Nearest-neighbor search in high-dimensional spaces. - I have two sets of 20K, 100-dimensional vectors each.\n- For each vector in set A, I want to find the closest vector in set B under Euclidean distance.\n- I need an exact algorithm.\n- I can afford some pre-processing time as I have quite a few of these sets, meaning I could construct an acceleration structure once per set and then re-use it for multiple queries.\n\nWhat's the best algorithm/data structure here?", "score": 63}, {"text": "Reductions in complexity theory: difference between oracle access or none?. I've seen two main ways people prove reductions of problems like X &lt;= Y. One definition I see for this is essentially that there is a computable function which maps instances of X to instances of Y such that if x in X then f(x) is in Y.\n\nI think I've also seen a definition like, if an algorithm can solve X with oracle access to Y, then X &lt;= Y. Can anyone explain if these definitions are equivalent? Is there a way to phrase say, a Karp reduction ([https://en.wikipedia.org/wiki/Polynomial-time\\_reduction#Many-one\\_reductions](https://en.wikipedia.org/wiki/Polynomial-time_reduction#Many-one_reductions)), under both interpretations?", "score": 60}, {"text": "Rice\u2019s theorem \u2013 an interactive tutorial I wrote. ", "score": 117}, {"text": "How to learn the intuition behind probabilistic arguments in Algebraic Complexity lower bounds. I was reading the lower bounds of arithmetic circuits. There in the proof of the theorem\n\n&gt; Over field F_q, determinant, permanent requires depth-3 circuits of size  2^\u03a9(n) [[Grigoriev, Karpinski, 1998]](https://www.researchgate.net/publication/2241304_An_Exponential_Lower_Bound_for_Depth_3_Arithmetic_Circuits)\n\nThey used a variant of the partial derivative matrix and used their rank to prove it. There they are randomly making a linear polynomial 0 then calculate the probability of that linear polynomial being 0 and finally proved it. [I started based on the idea I got from the proof. I may be wrong since I didn't understand the proof] \n\nAgain in the proof of the large rank of multilinear determinant and permanent of the partial derivative matrix, they are applying a random restriction on the variables to prove this.\n\nWhat is the intuition behind this type of argument? Why it is even valid? Please help\n\nI am reading from [Ramprasad Saptharishi's Survey ](https://github.com/dasarpmar/lowerbounds-survey/releases/download/v9.0.3/fancymain.pdf) \nAnd [Course on Arithmetic Circuits by Nitin Saxena](https://youtube.com/playlist?list=PLidiQIHRzpXJGO0-hQuEjGiuk9Zzfbw6e) (Here the things i mentioned are in lectures 13-16)", "score": 30}, {"text": "Isn't Lemma 2 enough to prove the FLP impossibility theorem?. I am watching a youtube lecture series on distributed consensus, and had some troubles understanding parts of the FLP impossibility theorem. I started reading the paper and it got me thinking: isn't lemma 2 enough to prove theorem 1?\n\ntheorem 1 states:\n\n&gt;THEOREM 1. No consensus protocol is totally correct in spite of one fault.\n\nlemma 2 states:\n\n&gt;LEMMA 2. P has a bivalent initial configuration.\n\nFor the sake of convenience, I'm going to address the message system as an agent (the operator) whose purpose is to dismantle the protocol\n\nthe paper rules out the trivial \"output 0\" strategy by saying that for some configurations an output of 0 may not be valid:\n\n&gt;The trivial solution in which, say, 0 is always chosen is ruled out by stipulating that both 0 and 1 are possible decision values, although perhaps for different initial configurations. \n\nbut if a bivalent configuration means both a 0 and a 1 configurations are reachable, that means that for an initial configuration where the decision of 0 is invalid, a deterministic protocol for the problem is impossible because a 0 configuration is always reachable, i.e the operator can force (or even by random chance) the processes to agree on 0 even when 0 is invalid.\n\nThen, why does the paper insist on proving the theorem by non-termination? Isn't this a sufficient proof? If it is, in what ways the non-termination argument is \"stronger\"?", "score": 60}, {"text": "Is there a possibility that all the current knowledge about computer science turns useless?. What happens when quantum computing advances? I'm currently studying a career in computer science and every time I think about it I get a little bit depressed. What if I'm learning all this for it turning into history? I love studying it and I'm certainly not doing it for money but the possibility of it being useless in the future and not having any application feels just depressing. Probably a very asked question but I just needed to post it, sorry", "score": 0}, {"text": "What are some compsci topics and algorithms that more people should know about?. Mine is Timsort, a fast sorting algo used by default in Python", "score": 174}, {"text": "What are the best practices for implementing the software architecture 'Microservices'?.  \n\nHi, I'd really appreciate if you could provide any response to this survey about Software Architectures and specifically implementing Microservices. It should only take 10 minutes. Please only participate if you have knowledge of Software Architectures, thanks!\n\n[https://docs.google.com/forms/d/e/1FAIpQLSc93l6VmoVrNW2rH95vLJdm44w6lLCn3hL0nF1wurvHjum0wg/viewform?usp=sf\\_link](https://docs.google.com/forms/d/e/1FAIpQLSc93l6VmoVrNW2rH95vLJdm44w6lLCn3hL0nF1wurvHjum0wg/viewform?usp=sf_link)", "score": 0}, {"text": "What might be a far future of computer science?. Recently I was talking with friends and we came across this topic (yeah, we are nerds): what might be a future of computer science?\n\nI guess we can immediately imagine quantum computing as the immediate next step of computer science, but then I was thinking, \"our current methods of computation are really really primitive\", and then postulated that the reasonable foreseeable end-future of computer science is artificial intelligence, but not the kind of AI that we see today, with matrices and what not. A different class of AI. Something which should be very close to AGI.\n\nSo here's my thoughts:\n\nWe can reasonably believe that quantum computing will be within close reach in perhaps this century. What this means would be that we are able to utilize very low levels of physical phenomena to do calculations, namely the quantum level and their spooky actions. We perhaps would be able to use individual atoms for calculation, and would probably stagnate for a while to let the physics etc catch up.\n\nBut eventually, we should be able to manipulate not just the individual atoms, but simple moleules to do calculations. And then larger mmolecules; aad then even large molecules, and eventually we should get to a point where we are ging into the field of \"chemo-computing\", where we throw around large molecles in a somewhat supervised manner and read the results.\n\nWith large molecules being done, we would focus on gigantic molecules, entering the field of bio-computing. Proto-DNA's would be used, and we perhaps would be able to answer unsolved questions on neurology, political science, and ethics: does free will scientifically exist? What exactly is consciousness and self-identity?\n\nFinally, this evolves into practical use of bio-infomatics, using bio-cells to store incomprehensible amounts of data as those information theorists have suggested possible. We would view life as some sorts of \"very very complicated machines\".\n\nWhich leads us back to artificial intelligence: with bio-computing being developed reasonably well, one can finally simulate human thoughts to a certain extent, which could be used to answer this very outlandish question: does a soul scientifically exist? Then, we would be very well equipped to tackle the topic of artificial intelligence, of which some had famously thought of as some sort of a small project completable over a summer.\n\nWe would not see true AGI as some sort of \"metallic\" algorithms and matrices as we see today; we would see AGI as a biological species hand-crafted by future computer scientists (or whatever name that they would take), using math and principles that we cannot comprehend today, with which the entire \"build process\" of life (i.e., developing from an \"embryo\" to a full life) is executed, culminating in what I would conveniently describe as \"manmade horrors beyond comprehension\": for example, what would they visually look like?\n\nBasically, \"synths\". Fleshy synths, instead of metallic synths.\n\nWe would then assign this species to the classification of AGI, and the understanding is complete: we have become gods, because we are able to create an entire new life capable of sentient thought with whatever exotic tool we might have in the future, and we have indeed created the AGI species in our own image.\n\nFeel free to ignore this post though, I feel like this is kind of a deranged post, but this feels reasonable somehow.", "score": 108}, {"text": "\"Linear Logic Programming\" by Chris Martens (2013). ", "score": 81}, {"text": "How does png to svg conversion work? Or is there any simpler way to represent a simple image into an equation like a brazier curve?. Edit: I want to represent the simple image like a stickman figure or some line drawing into the equation system like a bezier curve and I thought knowing how png to svg conversion work might help so I asked that. So, do you have any idea how to represent images with an equation.", "score": 55}, {"text": "What are the greatest breakthroughs in Computer Science?. I am interested in what are the biggest breakthroughs for you in Computer Science? I am asking since I want to explore more interesting topics for a podcast and also for some students of mine.", "score": 216}, {"text": "The baseline for Precision-Recall curve: A Bayesian approach. Hi,\n\nI've just published my recent article titled \"**The baseline for Precision-Recall curve: A Bayesian approach\".**\n\nThis article is a review of the nuts and bolts \ud83d\udd29 of Precision-Recall curve. Demystifying its baseline mathematically and empirically using some fun\ud83c\udf88**Python** codes for better understanding.\n\nlink: [https://itnext.io/the-baseline-for-precision-recall-curve-a-bayesian-approach-1611c690607](https://itnext.io/the-baseline-for-precision-recall-curve-a-bayesian-approach-1611c690607)", "score": 22}, {"text": "Good references for vector architectures. Title is pretty self-explanatory--I'm trying to design a (very limited-capability) vector processor more or less as a passion project, but I can't seem to find a good resource that assumes little more knowledge than what introductory computer architecture books cover yet also thoroughly explores the concept.   \n\n\nIdeally, I'd like for the book to cover both the ISA side of things as well as the actual circuits themselves (on a block level--registers and ALUs and such) so I can get a good idea of how things work.", "score": 67}, {"text": "Quantum Hype and Quantum Skepticism (2019). ", "score": 9}, {"text": "Mechanism of Bipartite Soft Matching. ", "score": 44}, {"text": "Subreddit/places where people review math proofs around software/computer science?. Title says it all I think.\n\nSay I submit a little proof in Latex (or not) and someone decides to take a peak and provides some feedback, shares knowledge and (hopefully constructively) criticize.\n\nGoal is to have fun writing formal math proofs of intuitive things maybe, learning how to model things using tools from math (e.g. use set theory to model relational database constructs), and maybe learn some tricks in Latex (or not).\n\nAnything out there for this?", "score": 103}, {"text": "Evolving two joined rigid bodies to throw another one the farthest. ", "score": 495}, {"text": "The End of Moore\u2019s Law: Silicon computer chips are nearing the limit of their processing capacity. But is this necessarily an issue? Copenhagen Institute for Futures Studies. ", "score": 17}, {"text": "Would this make bubble sort viable (Unlikely Hypothetical Scenario). If you could write the number 0 in the size of an atom, and you filled the observable universe with that many 0's. That with a 1 in front of it is N (leftmost digit is 1 followed by that many 0's). N^N is Z. \n\nA megabyte is 10^6 bytes. An Zbyte is 10^Z bytes. \n\nA computer X with a processing power of:\n5x10^Z Zbytes. Of ram I guess? Assume whatever else is required is met as appropriate. \n\nWould using a bubble sort be a good idea if you could use computer X? Would it be viable for current sorting requirements of a very big company like Google?\n\nNote: If not Ram, then assume (5x10^Z) * (10^Z) times faster than the current fastest supercomputer.", "score": 0}, {"text": "Coding Made AI\u2014Now How Will AI Unmake Coding?. ", "score": 82}, {"text": "Aren't all computational units of instructions generalizations from foundationally consistent sets of input-output relations?. ", "score": 57}, {"text": "How can P be contained in polyL?. Hi,\n\nI just read about polyL here: https://en.m.wikipedia.org/wiki/PolyL, and isn't their proof that polyL != P also proves that P isn't contained in polyL? They showed that there is a language A in P that isn't in polyL, that directly means P isn't contained in polyL.\n\nThanks!", "score": 49}, {"text": "The Path towards Building Multi-Stakeholder Recommendation Systems: Part-I. Most recommendation systems today are multi-sided, with multiple stakeholders. Consequently, the systems need to optimize for catering to various stakeholders (ex: consider uber eats, where you have the eaters, delivery partners &amp; restaurant partners - each with a  different set of expectations from the platform.)  - Find out how these systems are designed, optimized and explore the inner workings and learn how some parts of these systems are built in practice.\n\nIn a series of long articles -  we want to share our learnings on this topic. Towards that end, here is our first blog on the subject:\n\nhttps://preview.redd.it/mf5n7f24mst91.png?width=2424&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=151e35909e04688c840e66e84ea1bb3040957bd6\n\n[The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi-Objective Ranking in practice.](https://maxentlabs.com/blog/posts/post-1/marketplace-recsys-part-1.html)\n\nIn this First Part, we actually begin by explaining the Problem statement,  setting up background on common patterns of building recommendation systems in the industry today, methods of developing ranking models  (LTR), and popular metrics to evaluate ranking models &amp; then introduce various approaches to multiple objective optimizations applied to recommendation systems, and dive a bit into some examples from Etsy,  Linkedin &amp; Expedia to understand how this is solved in practice.\n\nIn the upcoming posts, we will expand on this subject in more detail and also look at sample implementation using the popular H&amp;M  recommendations dataset.\n\nCheck this out, and let us know if you find something missing here or would like to be covered or maybe suggest improvements.", "score": 69}, {"text": "CMU-HoTT/scott: Selected Papers of Dana S. Scott [PDFs, scans]. ", "score": 75}, {"text": "Are encrypted login checks susceptible to timing attacks?. It seems that timing attacks are only relevant to short-circuited plain text comparisons. Do they show up in short-circuited hash comparisons? And if so, are the timings of hashes actually beneficial to a hacker, despite two similar passwords having very different hashes?", "score": 75}, {"text": "Cantor's Lemma Rigorous and Visual Proof!. Dear friends,\n\nI would like to share with you the following proof of Cantor's lemma that I spent many hours preparing.\n\nI'm very happy with the rigor in the proof as well as with the detailed visualization and the emphasis on intuition and understanding that I make in this video.\n\nYou will be the ultimate judge of those statements.\n\nI hope that at least some of the people who read the post up until this point will find it useful.\n\nRecommend watch speed x1.5-x2 :) :) :).\n\nEnjoy:\n\n[https://www.youtube.com/watch?v=ijMvFprZqbU&amp;ab\\_channel=Math%2CPhysics%2CEngineering](https://www.youtube.com/watch?v=ijMvFprZqbU&amp;ab_channel=Math%2CPhysics%2CEngineering)", "score": 17}, {"text": "A hash table that uses less space than the items it stores. This blog post constructs a hash table with a seemingly impossible space guarantee: it can store n 32-bit items in **less** than n \\* 32 bits of space. That is, the hash table uses less space than it would take to write the elements down, one after another, in an array. \n\n[https://algorithmsoup.wordpress.com/2022/10/09/a-hash-table-that-uses-less-space-than-the-items-that-it-stores/](https://algorithmsoup.wordpress.com/2022/10/09/a-hash-table-that-uses-less-space-than-the-items-that-it-stores/)\n\nThe hash table is surprisingly fast (on par with the C++ std library). But my guess is that it could be made much faster still if someone was willing to put some effort into it.", "score": 69}, {"text": "A vague question about linguistics and programming languages. In English, the structure of a sentence is predominantly determined by the order of words in it. (I\u2019m not sure what other western languages have that design.) In other western languages the structure is determined by the endings of words.\n\nThis means ambiguities in English are not ambiguous in those other languages. For instance, \u201cI like Mom more than Dad\u201d can mean either that I like Mom more than I like Dad, or it can mean I like Mom more than Dad likes mom. This ambiguity would not be present in other languages, where the case of the word meaning \u201cDad\u201d would either be accusative or nominative, respectively.\n\nIs there an analogous dichotomy in programming languages?", "score": 123}, {"text": "Matrix Multiplication as Tensor Decomposition - A blog on the DeepMind paper.  Hi r/compsci\n\nI wrote a short blog post about the recent paper on Matrix Multiplication. I curate some expert opinions from twitter and give a breakdown of the Tensor trick used in the paper.\n\n[https://sudeepraja.github.io/MatrixMultiplication/](https://sudeepraja.github.io/MatrixMultiplication/)\n\nI appreciate all corrections and feedback.", "score": 106}, {"text": "Call for Applications: 100 grants - \u201cSao Paulo School of Advanced Science on Contemporary Logic, Rationality and Information\u201d, February 2023 at CLE/Unicamp, Brazil. \\*With apologies for cross-posting\\*\n\n&amp;#x200B;\n\nCall for Applications: 100 grants - \u201cSao Paulo School of Advanced Science on Contemporary Logic, Rationality and Information\u201d, February 2023 at CLE/Unicamp, Brazil.\n\nSponsored by the S\u00e3o Paulo Research Foundation - FAPESP, &lt;[https://fapesp.br/](https://fapesp.br/)\\&gt;.\n\nAdditional support provided by the Brazilian Logic Society - SBL, &lt;[http://www.sbl.org.br/](http://www.sbl.org.br/)\\&gt; and by the Association for Symbolic Logic - ASL &lt;[https://aslonline.org/sponsorship-of-meetings/](https://aslonline.org/sponsorship-of-meetings/)\\&gt;.\n\nImportant deadlines &amp; procedures:\n\n\\- Applications from October 1st to October 30th, 2022\n\n\\- Notification of acceptance till November 30th, 2022\n\n\u00a0\\-Fast application track:\n\n[https://www.cle.unicamp.br/splogic/index.php/call-for-entries/](https://www.cle.unicamp.br/splogic/index.php/call-for-entries/) \n\n\\- For further\u00a0info: [splogic@unicamp.br](mailto:splogic@unicamp.br)\n\n\u00a0\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*We are delighted to inform that, after having been postponed due to the COVID pandemics, the \u201cSao Paulo School of Advanced Science on Con\\\\temporary Logic, Rationality and Information \u2013 SPLogiC\u201d, promoted by the Centre for Logic, Epistemology and the History of Science (CLE) of the University of Campinas (Unicamp), Brazil, will be held at Unicamp from February 6th to 17th, 2023.\n\nThe School, funded by the\u00a0 Sao Paulo Research Foundation (FAPESP), celebrates the 90th anniversary of\u00a0Newton da Costa and the 45 years of CLE, and aims at:\n\n\\- Providing\u00a0an overview of the state-of-art methodology and research on contemporary logic (featuring non-classical logics), rationality and information.\n\n\\- Attracting\u00a0qualified candidates to work at research institutions in the State of S\u00e3o Paulo.\n\nThe program comprises 8 courses and 9 plenary talks delivered in English by experts in each topic, as well as oral presentations (LED Talks) and poster sessions by the students.\n\nTopics to be covered include:\n\n\u2022 History and Philosophy of Paraconsistent Logics\n\n\u2022 The Australian, Belgian Brazilian, and Israeli and Polish\u00a0schools on paraconsistency\n\n\u2022 Logic and Reasoning\n\n\u2022 Logic and Information\n\n\u2022 Logic and Argumentation\n\n\u2022 Methodological aspects on interpreting, translating and combining logics\n\n\u2022 Logic, Probability and Artificial Intelligence.\n\nThe event will select 100 fully-funded participants (50 grantees from all states of Brazil and 50 international grantees). Funding includes airfare, medical insurance, accommodation and meals     throughout the two weeks.\n\nUndergraduate, graduate students and postdoctoral fellows (up to 5 years after completion of the Ph.D) from all countries are encouraged to apply.\n\nFor additional information, and to apply, visit the WebSite: [https://www.cle.unicamp.br/splogic/](https://www.cle.unicamp.br/splogic/)\n\n&amp;#x200B;\n\n\\*\\*Please circulate!\\*\\*\n\n&amp;#x200B;\n\nWe look forward to receiving you!\n\nItala M. Loffredo D\u2019Ottaviano, Academic Chair\n\nWalter\u00a0 Carnielli, Advisory Committee Chair", "score": 87}, {"text": "One-Page Reports on Seminal Cloud/Distributed Systems Papers. Hi everyone,\n\nOver the past month, I've been uploading one-page reports on seminal papers in this field. The one-page reports are formatted in the following order: 3-5 lines summary, 1-3 major strengths of the paper (i.e., what's  *cool* about this), a weakness, and future work opportunities. The goal of these reports is not to skip reading the paper in its entirety, but rather to peruse the ones with reports that spark interest. Yesterday, I uploaded my tenth report. I intend to write and share more of these reports because it helps me absorb the material. My goal, other than writing better reports, is to start writing such reports on seminal papers from other fields too.\n\n**Reports (as of 10/05/22)**\n\n* Epidemic Algorithms for Replicated Database Maintenance by Alan Demers et al. (1987)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#epidemic) \\#1\n* Simple Approach to Specifying Concurrent Systems by Leslie Lamport (1989)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#simple_approach) \\#2\n* Use of Formal Methods at Amazon Web Services by Chris Newcombe et al. (2014)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#formal_methods_aws) \\#3\n* Hints and Principles for Computer System Design by Butler Lampson (2020)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#hints_and_principles) \\#4 for sections up to and including \u00a73.4\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#hints_and_principles) \\#5 for \u00a73.5 and beyond\n* Chain Replication for Supporting High Throughput and Availability by Robbert van Renesse and Fred B. Schneider (2004)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#chain_replication) \\#6\n* End-to-end Arguments in System Design by J.H. Saltzer et al. (1984)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#end_to_end) \\#7\n* Distributed Snapshots: Determining Global States of Distributed Systems by K. Mani Chandy and Leslie Lamport (1985)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#distributed_snapshots) \\#8\n* On the Duality of Operating System Structures by Hugh C. Lauer and Roger M. Needham (1979)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#duality) \\#9\n* ghOSt: Fast &amp; Flexible User-Space Delegation of Linux Scheduling by Jack Tigar Humphries et al. (2021)\n   * [Report](https://ritwiktakkar.com/blog_paper_reviews.html#ghost) \\#10", "score": 53}, {"text": "Computational complexity of reversing conway's game of life in a finite grid?. Yes, I'm aware there isn't just one predecessor to a grid state (sometimes there aren't at all), but on average, how difficult is it to find some finite grid state that precedes a given state (provided the grids are the same size, and it is reversible at all)? \n\nI'm particularly interested in the range where this problem stops being a sub-second problem, even with efficient algorithms.\n\nI wrote a simple [program](https://gist.github.com/rubydusa/f718ef52203f2c29798a0063f48eb1a3) in prolog to reverse a given state using an integer constraint solver library. I use a variant of the game of life where values wrap around the edges.\n\nJust from playing around it seems that for a 7x7 grid it's still relatively fast, but for a 8x8 grid it takes a couple of seconds most of the times. I used first fail variable labeling strategy (assign to the most constrained variable first) which seems optimal but maybe I'm experiencing computational overhead from prolog.\n\nAny insight and discussion about the topic is appreciated!", "score": 55}, {"text": "What is that one obscure, perhaps neglected/random Theorem or Law you learned in class that is actually relevant to your job?. I'll go first:\n\nFor me, it's DeMorgan's Law. This Law first gets taught in your Discrete Structures/Discrete Mathematics course, and it is a law regarding logical equivalences. It goes somewhat like this:\n\n!(a and b) = !a or !b  \n!(a or b) = !a and !b\n\nI'm a SQL programmer, and the concept of logical equivalences is extremely important when trying to include/exclude data.", "score": 325}, {"text": "Discovering novel algorithms with AlphaTensor. ", "score": 41}, {"text": "Epsilon nets and covering arguments in hamming space. I'm working on a problem where it's necessary for me to compute the doubling dimension of a metric space. Doubling dimension is essentially the number of balls of radius r/2 needed to cover a bigger ball of radius r. For Euclidean space with standard LP norm, it's known that 2^d balls are needed it follows from covering arguments.\n\nHowever my space is not Euclidean but rather binary {0,1}^d and the metric is hamming distance. This seems related to error correcting codes (not my field at all) but I haven't anything that Cav answer my question. But I'm wondering if there are known/standard bounds for covering or doubling in Hamming spaces that could be useful here.", "score": 1}, {"text": "PH = PSPACE?. Using PSPACE-completeness of quantified boolean logic Valerii Sopin claimed to have obtained that **PH = PSPACE**, see [https://arxiv.org/abs/1411.0628](https://arxiv.org/abs/1411.0628)\n\n*True quantified Boolean formula is indeed a generalisation of the Boolean Satisfiability Problem, where determining of interpretation that satisfies a given Boolean formula is replaced by existence of Boolean functions that makes a given QBF to be tautology. Such functions are called the Skolem functions.* \n\n*The essential idea of the proof is to skolemize, and then use additional formulas from the second level of the polynomial hierarchy inside the skolemized prefix to enforce that the skolem variables indeed depend only on the universally quantified variables they are supposed to. However, some dependence is lost when the quantification is reversed. It is called \"XOR issue\" because the functional dependence can be expressed by means of an XOR formula. Thus, it is needed to locate these XORs, but there is no need to locate all chains with XORs: any chain includes a XOR of only two variables. The last can be done locally in each iteration (keep in mind the algebraic normal form (ANF)), when all arguments are specified.*\n\n&amp;#x200B;\n\n**Relativization** is defeated due to the well-known fact: PH = PSPACE iff second-order logic over finite structures gains no additional power from the addition of a transitive closure operator. Boolean algebra is finite. The exchange is possible due to finite possibilities for arguments. So, the theorems with oracles are not applicable since a random oracle is an arbitrary set. And that\u2019s why Polynomial Hierarchy is infinite relative to a random oracle with probability 1.", "score": 64}, {"text": "Knuth's TAOCP Volume 4B is coming SOON.. First of all, sorry if this was already posted, I couldn't find any reference on this subreddit.\n\nLooks like the long awaited TAOCP 4B, or more formally,  \"Combinatorial Algorithms, Part 2\" will be available on 11 October, i.e. ten days from now! I'm quite excited, this will be one of the most interesting books in the series.\n\nSee [Knuth's page on the books](https://www-cs-faculty.stanford.edu/~knuth/taocp.html) for reference.\n\nhttps://preview.redd.it/nmr43ysju5r91.png?width=1053&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ef3ddb1d481227fb89f019e058940ffc20fba436", "score": 208}, {"text": "Confused on Inductive Step in Helly\u2019s Theorem. ", "score": 4}, {"text": "Posits, a New Kind of Number representation, Improves the Math of AI. ", "score": 132}, {"text": "Visual Proof For 1^2+...+n^2 (3D Puzzle assembly). Dear Friends,\n\nI would like to share with you this visualization for the formula\n\n1\\^2+...+n\\^2=n(n+1)(2n+1)/6.  I hope you will enjoy seeing the visual proof manifesting itself as an assembly of a 3D puzzle.\n\nThis video was prepared using the manim library.  \n\nEnjoy:\n\n[https://www.youtube.com/watch?v=NZaEQFn1LGY&amp;ab\\_channel=Math%2CPhysics%2CEngineering](https://www.youtube.com/watch?v=NZaEQFn1LGY&amp;ab_channel=Math%2CPhysics%2CEngineering)", "score": 64}, {"text": "Why do we still use Hopcroft\u2013Karp algorithm for maximum cardinality matching?. I've been doing research into maximum cardinality matching for a project. Most sources talk about the  Hopcroft-Karp algorithm. Some of them mention that the problem can be turned into a network flow problem and use the Ford\u2013Fulkerson algorithm.\n\nBut both of these algorithms are old and slow. There's been 50 more years of research on the topic since these algorithms were published, and many faster algorithms for solving network flow have been found. Just a few months ago, a [near-linear time algorithm was discovered](https://www.quantamagazine.org/researchers-achieve-absurdly-fast-algorithm-for-network-flow-20220608/).\n\nSo my question is, why is Hopcroft-Karp still recommended by so many places (geeksforgeeks, stack overflow, wikipedia, random programming blogs)? Is it because the faster algorithms are more complex? Or do the newer algorithms only work in special cases?", "score": 82}, {"text": "A question that came to mind. Given an int m, an int n, and an array of ints R, find all sets of size n with (distinct) integers between 1 and m such that no difference of two numbers in the set is an element in R, and such that 1 is an element in the set.\n\n\nEDIT: A lot of people thought I was trying to get solutions for a t-a-s-k (I'm being extra careful in avoiding bots), but this question originally started when I thought about how many musical scales of a certain span don't contain a tritone, and other unwanted intervals. This is essentially the same question just written in a different way, and is also considerate of stuff like microtonality.", "score": 94}, {"text": "Python Turtle Library (A Quick and Easy way to draw and visualize). Dear Friends,\n\nWanted to share with you this nice visualization I did with the Python Turtle library.\n\nIn this video, I show how to visualize the famous Zeno's Mice problem.\n\nAt first, I qualitatively describe the problem,\n\nthen show visualization with Python Turtle, code available in the description of the video.\n\nIt is mostly based on the code of the python turtle academy.\n\nThen I also show that those curves are actually all around us.\n\nFinally, I show a simple and elegant solution to a system nonlinear system of coupled ordinary differential equations. Using symmetry we can reduce the system to a single equation.\n\nComplex numbers also help simplify the solution.\n\nFinally, I show how such behavior happens in ants in real life.\n\nEnjoy:\n\n[https://www.youtube.com/watch?v=NdTVvWrD6r0&amp;t=5s&amp;ab\\_channel=Math%2CPhysics%2CEngineering](https://www.youtube.com/watch?v=NdTVvWrD6r0&amp;t=5s&amp;ab_channel=Math%2CPhysics%2CEngineering)", "score": 70}, {"text": "Managing Documents using Blockchain Technology. Hype or a real application for blockchain?. ", "score": 0}, {"text": "A* vs BFS in snake game. ", "score": 946}, {"text": "Exploring Time &amp; Order In Distributed Systems. ", "score": 31}, {"text": "Can you efficiently solve this problem?. ", "score": 257}, {"text": "Nonpolynomial November. I'm tired of people talking about how important NP-complete problems are and how they take too long to solve.  That's why I'm creating Nondeterministic November.  \\[The title of the post is incorrect because I had to fix the name and can't fix the post title.\\]\n\nThis is a game jam (really more of an algorithm jam) in which participants work on NP-complete problems.  This can include projects like:\n\n* Solve an NP-complete problem.\n* Convert an NP-complete problem into another NP-complete problem.\n* Prove that a problem is or isn't NP-complete.\n* Write a mathematical proof of whether P=NP or not.\n* Find some new application for an NP-complete algorithm.\n* Allocate more computing resources to an NP-complete problem.\u00a0 For instance, this could be using the graphics card to perform mathematical computations.\u00a0 Or it could be multi-threading or using a network of computers.\n\nAt a practical level, I plan to make myself a toolkit for solving NP-complete problems.  At a grander level, I want to experiment with solving them in different ways.  I want to gather thousands of people to each work on this in November.  My hope is that a large enough body of people might be able to discover something new.\n\nThis jam is intended for people that have some background in computer science or mathematics, but aren't particularly invested in NP-complete problems.  There's no limitation on who can participate, but I feel like people who don't have the necessary knowledge won't benefit.  And computer science graduate students don't need me to tell them to work on solving NP-complete problems.\n\nThere's no ranking and no prize for the jam, but the Clay Institute is offering $1 million to anyone who can prove whether P = NP.\n\nLink:\n\n [Nondeterministic November - itch.io](https://itch.io/jam/nondeterministic-november)\n\n&amp;#x200B;\n\nEdit: Fixed name.", "score": 2}, {"text": "langcc: A Next-Generation Compiler Compiler. langcc is a tool that takes the formal description of a language, in a standard BNF-style format, and automatically generates a compiler front-end, including data structure definitions for the language's abstract syntax trees (AST) and traversals, a lexer, a parser, and a pretty-printer. \n\nhttps://github.com/jzimmerman/langcc", "score": 58}, {"text": "Some Questions about Time Complexity and Space Complexity. When working through some programming questions regarding time and space complexity I came across a thought that made me step back and think about the benefit of asking for a person to write a question within a a certain set of time and space complexity and how it doesn't really say how efficient an algorithm might perform.  \n\nI'm going to use an example question of iterating through a string of alphabet characters and counting each of their appearances to try and illustrate my point.\n\nMy understanding is this: if an algorithm is asked to have O(1) space complexity it means that the amount of memory used by the algorithm is constant across every iteration over the input. By this logic lets say we created an array where each index is a different possible ASCII value (so the array would 256 elements) and then just incremented the appropriate index for every letter we get in our string we are iterating over. This would have the same space complexity if instead the array we created was only 26 elements characters in size (since we know beforehand the string only has alphabet characters).\n\nclearly one array uses more space then the other and therefore if you didn't know how the program was written beforehand and say both algorithms are completed using O(1) space complexity it kind of glosses over the the fact that one array uses the space way more efficiently then the other.\n\nMy point also stands with regards to time complexity because you could for example say an algorithm has a O(1) time complexity if instead of depending on the length of the inputs it just looped through all the possible values for an integer for every input and therefore looped a constant amount of time for each individual input.\n\nI guess the point I am trying to get across is that saying a certain algorithm has a certain time complexity or space complexity doesn't fully explain how efficiently an algorithm might be working with the input, I was wondering if my reasoning in this was correct, or is there something I am misunderstanding with time complexity/space complexity in general.", "score": 31}, {"text": "Is there a special name for a graph with node values and edge weights. A graph that has nodes, edges, and edge weights is a weighted graph. There is also a weighted directed graph.\n\nWhat do you call a graph that also has node values? If there is not a special name for this graph, is it because there is always a way to convert it into a weighted graph?\n\nSpecifically, I am designing a game where node values represent rewards and edge weights represent the time to travel between nodes. The player must get the maximum score in an allotted time. I want to know how close to optimal the player's choices were to give them a score. Is there a way to represent this as a weighted graph? If not, is there a name for a graph with node values and edge weights?", "score": 63}, {"text": "\"Degrees\" of instability for unstable sorting algorithms?. ", "score": 39}, {"text": "My best attempt to explain compactness and the Heine Borel theorem. Dear Friends,\n\nI have prepared this quite long video and put many hours of work into it.  If you want to see visually and in great detail the idea behind the proof of the Heine-Borel theorem, this video is for you and I PROMISE it will be worth your time.\n\nI could have made several shorter videos, but this would have disrupted the logical cohesion of this video.\n\nFirst, we recall the definition of open sets of the real line and define open covers.\n\nThen we demonstrate an open cover of (0,1) that has no finite subcover.\n\nThen we show visually in great detail why the interval \\[0,1\\] is compact with emphasis on intuition.\n\nThen I show a very detailed and very rigorous proof. I also mention the connection between compactness and sequential compactness.\n\nDavid Hilbert once said: \"the art of doing mathematics is identifying those special cases that contain all the germs of generality.\"\n\nI have tried to design this video and this calculus 1 course that I'm recording in the spirit of this statement.\n\nThis theorem is very deep and hard. In order to prove it one needs:\n\n1. The Zermelo Frankel Axioms to set the foundation of Real Numbers\n2. The Completeness axiom on which all of the analysis relies and the reason that Cantor's lemma works and that Cauchy sequences must converge.\n3. Also later in this playlist, we will see the use of the axiom of choice.\n\n&amp;#x200B;\n\nEven in this first introductory calculus course, I try to show early on the ideas of metric spaces, topology, compactness, and sequential compactness, and later on, I also plan to introduce connectedness and continuity.\n\nWith all modesty, I must say that I'm very happy with how this video came out.\n\nEnjoy:\n\n[https://www.youtube.com/watch?v=3KpCuBlVaxo&amp;ab\\_channel=Math%2CPhysics%2CEngineering](https://www.youtube.com/watch?v=3KpCuBlVaxo&amp;ab_channel=Math%2CPhysics%2CEngineering)\n\nLink to the full playlist:\n\n[https://www.youtube.com/watch?v=7WFw9jOy\\_oA&amp;list=PLfbradAXv9x5az4F6TML1Foe7oGOP7bQv&amp;index=4&amp;ab\\_channel=Math%2CPhysics%2CEngineering](https://www.youtube.com/watch?v=7WFw9jOy_oA&amp;list=PLfbradAXv9x5az4F6TML1Foe7oGOP7bQv&amp;index=4&amp;ab_channel=Math%2CPhysics%2CEngineering)\n\nThank you all for reading up to this point!", "score": 95}, {"text": "I visualized the Idea behind the Master Theorem. Here the Video: [https://youtu.be/d-gIGFxewW4](https://youtu.be/d-gIGFxewW4)\n\nThe math behind it can be found in \"Introduction by Algorithms\" by Cormen et al.\n\nI simplified the third case a bit for clarity.", "score": 142}, {"text": "Visualized Proof of the Bolzano-Weierstrass Theorem using Cantor's lemma. Dear Friends,\n\nI hope that at least some of you will enjoy watching the visual proof of the BW theorem:\n\n[https://www.youtube.com/watch?v=kS4uEGmxT-8&amp;ab\\_channel=Math%2CPhysics%2CEngineering](https://www.youtube.com/watch?v=kS4uEGmxT-8&amp;ab_channel=Math%2CPhysics%2CEngineering)\n\nHere I show the intuition in detail first and then construct the rigorous proof.\n\nThe reasoning in this proof is very similar to the reasoning behind the classical binary search algorithm.", "score": 73}, {"text": "A group of computer scientists and biologists got together and tested 384 asymptomatic patients using just 48 tests: they caught four positive patients and concluded the rest were negative. I made a video going through the math/computer science behind them being able to do this. Link is in the post.. Here's the link to the video:\n\n[How researchers saved on covid tests by finding values of polynomials - YouTube](https://www.youtube.com/watch?v=D4wFd3iARWA&amp;ab_channel=FineDesign)\n\nHere's a transcript of the video if you just want to read it instead of watching it:\n\n[https://pastebin.com/F3K11aXq](https://pastebin.com/F3K11aXq)", "score": 136}, {"text": "How to understand Quantum Computing?. I am currently enrolling myself into a CS course. And I would also like to know how I can teach myself mathematics to understand the concept of quantum computing. What kind of mathematics do I need to learn in order to understand quantum computing?", "score": 131}, {"text": "I created a website that shows the effects of different noises and filters and their combinations on images. I plan to add more filters, like lowpass, and deep learning methods. Link to the website and GitHub are in the comments.. ", "score": 291}, {"text": "Verification of computation without re-executing the computation. In a network of distributed state machines, each peer runs a function of `validate(currentState, incomingState) == true`. While the first peer has to run the computation, is it possible that other peers verify the result without complete re-computation (at least optimized) ? Verifiable computing seems to be all about ZK proofs which doesn't exactly suit this use case, as we don't need to hide inputs. \n\na quote from a random person i talked with. \n\n&gt; So HVM isn't about parallel computation in the way I described. What I described was. If I evaluate the program `let c = a / b; let d = a + b; let f = d + c`, I can trace the values c, d, and f when running the program once, and then replace let c = a / b with assert a = b * c, assert d = a + b, assert f = d + c, where we know a and b from the start, but we also learned the trace values c, d, and f. Note in the first case, we replace slow division with a multiplication, to validate the proof without evaluating the slower division. The trace breaks dependencies and allows us to verify everything concurrently. The rewrite applies the identity assert c = a / b is equal to assert a = b * c, where the latter is cheaper, so we prefer it.\n\n&gt; You can start with a simple WASM interpreter, it can be slow, because there are few provers (the users, and the few nodes who observe multiple states which need to be merged); and we want to optimize for verification.\n\n&gt; The trace simply extracts intermediate terms, to transform code like let c = a / b; let d = a + b; let f = c + d from a list of lets to a list of asserts where we already have each result. assert c = a / b includes a pattern we can optimize, and rewrite to assert a = b * c. These assertions can all be checked in parallel, and if any fail, we can interrupt any other workers because we don't care about other work.\n\n&gt; While the prover may need the complete program, the verifier only needs the traced path through the program. Ex. if true then solve puzzle 1 else solve puzzle 2 only includes the former solution, while the latter can be discarded.\n\nand a quote from a related article \n\n&gt; There is this massively replicated set of machines that run the contracts. I already know it's valid, I don't need everyone to recompute it. It's much neater to just be able to prove it's valid, without everyone needing to recompute everything. The typical example is that say I have a program that needs to divide two numbers, division is a complex operation but instead I can provide an extra input where I say this is the result of the division and it does multiplication to verify. If you take that to an extreme, you get a different language approach and a more functional language where you describe a condition for spending.", "score": 25}, {"text": "Are there any interesting implications of a Turing machine simulating itself?. Had this random thought and I'm sure this is a well studied idea. Clearly a Turing machine can simulate itself, or simulate another Turing machine simulating another Turing machine simulating another Turing machine and so on, possibly infinitely many times. Is there anything interesting that comes out of this idea, for example implications for decidability or complexity analysis?", "score": 105}, {"text": "A question about multi-threading. Does it make any sense that when I double the number of threads being used in a program I get x3 the performance instead of x2 ? Shouldn\u2019t the performance be linear with the number of threads ?\n\nEDIT: To provide more context the analysis was being made to compare before a function that exists in a tool that supports multi-threading vs the same function but implemented on Apache Spark in a distributed environment. The results I got when I increased the number of threads from 2 to 4 showed that I gained 3x the performance instead of just doubling it", "score": 15}, {"text": "I have made a simple search algorithm that's much faster than the linear search, but it only works in unsorted lists containing consecutive numbers. Is this useful in any case whatsoever?. It probably isn't useful, but I want to make sure of it before I dump the  idea.", "score": 0}, {"text": "My Logisim RISC-V Computer executing Dijkstra's Shunting Yard algorithm written in C to evaluate single digit arithmetic expressions.. ", "score": 541}, {"text": "\"Category Theory for Programming\", by Benedikt Ahrens and Kobe Wullaert [abstract + link to PDF, 76pp]. ", "score": 130}, {"text": "Federated Learning: A Distributed Shared Machine Learning Method. https://lausr.org/dashboard/?doi=10.1155/2021/8261663", "score": 30}, {"text": "Spent Some Time Reading A Paper On Accrual Failure Detectors So You Don\u2019t Have To. ", "score": 42}, {"text": "Are there any undecidable problems about DFAs/ regular languages?. See title. With DFAs and their equivalents, acceptance testing, emptiness, equivalence, etc. are all decidable. When you move to more powerful models of computation, at least some of these become undecidable, and eventually you reach Turing machines, where all of the listed problems are undecidable (and with equivalence, neither it nor its complement are even recognizable!). It's enough to make one wonder if there are *any* undecidable problems about DFAs at all. \"About DFAs\" is admittedly perhaps too vague, but I should note that I don't include problems which involve DFAs and more powerful models of computation (e.g. checking whether a TM's language is regular), nor problems about variants of DFAs that have more computational power; I'm looking only for problems about \"ordinary\" DFAs and equivalents like NFAs, regexes, etc.", "score": 67}, {"text": "In your opinion, what's the most advanced topic or sub-field in computer science?. ", "score": 156}, {"text": "VkFFT now supports Rader's algorithm - A100 and MI250 benchmarks: Part 2. Hello, I am the creator of the [VkFFT](https://github.com/DTolm/VkFFT) \\- GPU Fast Fourier Transform library for Vulkan/CUDA/HIP/OpenCL and Level Zero. Two weeks ago I made a [post](https://www.reddit.com/r/compsci/comments/wr12no/vkfft_now_supports_raders_algorithm_a100_and/) about [Rader's algorithm](https://en.wikipedia.org/wiki/Rader%27s_FFT_algorithm) implementation in VkFFT, which improved the performance of VkFFT for sequences not decomposable as small primes multiplication.\n\nThe previous version of VkFFT was doing direct multiplication convolutions of length N-1 to create an FFT kernel of an arbitrary prime length to be used in a regular Stockham FFT algorithm. Direct multiplication convolutions scale as O(N\\^2) and do not work well for primes after 100.\n\nThis update brings support for the [convolution theorem](https://en.wikipedia.org/wiki/Convolution_theorem) Rader's algorithm, which no other GPU FFT library currently has. The new version does the Rader algorithm by inlining an FFT convolution in the FFT code - with FFT convolution having O(NlogN) complexity. So it works well for ALL primes - 127, 241, 811, 5501, 7001 and so on, only excluding the Sophie Germain safe primes. The Sophie Germain safe primes are the primes that have (P-1)/2 as a prime, like 59 or 83. In general, it is possible to inline more convolutions inside the convolutions (do 59 as a 58 convolution, 58=2\\*29, do 29 as a 28 convolution...), but for GPUs, this won't work, which I will explain later.\n\nSo now VkFFT can generate radix kernels for all primes up to the GPU's shared memory limit (\\~10000 for A100). Below I present the performance improvements of the new Rader's algorithm. The benchmark used is again a batched 1D complex to complex FP64 FFT for sizes 2-4096. We use the achieved bandwidth as a performance metric - it is calculated as total memory transferred (2x system size) divided by the time taken by an FFT, so the higher - the better. A100 VRAM memory copy bandwidth is \\~1.3TB/s. VkFFT uses CUDA API.\n\nhttps://preview.redd.it/codh3jg53vl91.png?width=2896&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2b22f99d7752d743d2b6c2c4928e50f266625e7b\n\nAs we can see, the FFT version of Rader's algorithm greatly outperforms the multiplication version used in cuFFT and has bigger prime range support. For primes up to 100, the performance of it is comparable to native radix kernels - systems operate at the full global memory bandwidth, which is the limit for any implementation. And VkFFT can combine them in one kernel, doing sequences like 17\\*19\\*23 in one upload.\n\nAs we increase the primes, performance decreases mainly due to two factors: shared memory bandwidth and decreased occupancy. The shared memory of a GPU is fast (15TB/s per CU), but not infinitely fast. and Rader's FFT has 2x the regular shared memory communications as it does FFT and IFFT. Profiling shows that this limits the performance, and similarly to global memory bandwidth, not much can be done about this. This is also the reason why Sophie Germain safe primes won't work well on a GPU - each of them will multiply the Rader's shared memory communications by a factor of 2. The occupancy decreases as VkFFT tries to minimize global memory communications - increasing the on-chip workload. Some primes can take all the registers and shared memory available, limiting the number of executed in-parallel kernels. This results in schedulers not being able to hide dispatch latencies due to having to wait for previous results. Abstaining from the global transfers minimization model will instantly drop the performance by 2x and this will alleviate all the possible gains.\n\nNow coming to AMD's MI250 (single chip version), the peak copy bandwidth is 1.3TB/s. The same benchmark configuration. VkFFT uses HIP API.\n\nhttps://preview.redd.it/hcjla5x53vl91.png?width=2896&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=bedc65a12efd219bf85797f36796d9c4b3f994ff\n\nThe same analysis as for A100 holds for MI250, except that it has a lower shared memory size (MI250 has 64KB of it) and lower shared memory bandwidth, limiting the potential performance (which is still better than Bluestein's algorithm).\n\nThis concludes Rader's algorithm implementation in VkFFT. I will try to make a paper on how GPU resources are managed in it and how it was possible to make it work together with other algorithms like the Stockham algorithm and R2C/R2R optimizations, while still maintaining the lowest possible number of global memory transfers (and also optimize for all modern GPU architectures).", "score": 30}, {"text": "Categorical composable cryptography: extended version. \"We ... show that protocols secure against abstract attacks form a symmetric monoidal category, thus giving an abstract model of composable security definitions in cryptography.\" [abstract + link to PDF, 34pp]. ", "score": 61}, {"text": "Busy Beaver Updates: Now Even Busier. ", "score": 127}, {"text": "What are some examples/applications of propositional, predicate, and higher-order logic?. Here's one explanation I saw: \n\n&gt; first-order logic is predicate calculus where quantification is restricted to individual variables (variables ranging over \"objects\") and quantification over predicate variables (i.e. variables ranging over \"properties\") is not allowed\n\nAt first glance I know what these words mean, but at the same time I feel like I don't really understand what is going on. What does it actually mean to \"do\" logic? Aren't we automatically \"doing logic\" on a daily basis? For example, if a car is on then the engine is running, so by *[modus tollens](https://en.wikipedia.org/wiki/Modus_tollens)* if the engine isn't running then the car isn't on. But any 4 year old can make this inference, and they don't need to know what modus tollens is to do it. So how is logic actually used?\n\nI've tried looking this up and read that AI is one of the main use cases, but I never see any actual examples of how it's used in AI, just very abstract definitions that I don't know what to do with. Unlike an abstract description of an algorithm or data structure, which I can instantiate and use in the real world, I'm just not sure what to *do* with the concepts and rules of logic.", "score": 51}, {"text": "I taught a neural network to play Flappy Bird with Java/Kotlin. ", "score": 1078}, {"text": "Are you interested in computer history? Smalltalk turns 50 on September 1. Celebrate its birthday online with the Computer History Museum and many Smalltalk luminaries of the past 50 years.. Are you interested in computer history? Smalltalk turns 50 on September 1.\n\n[You can reserve a free online ticket with the Computer History Museum for the online celebration, featuring Smalltalk alumni from 50 years ago.](https://computerhistory.org/events/making-smalltalk/)\n\n________\n* .\n\n 5 p.m. PDT \n\n Member Check-In  \n \n .\n\n 5:30 p.m. PDT  \n\n Members only program with Adele Goldberg, Rachel Goldeen, Bruce Horn, Dan Ingalls, Ted Kaehler, and Glenn Krasner in conversation with Dave Robson \n \n .\n\n 6:30 p.m. PDT  \n\n Program Check-In  \n \n .\n\n 7 p.m. PDT  \n\n Program begins with Smalltalk pioneers Adele Goldberg and Daniel Ingalls in conversation with Pulitzer Prize-winning New York Times reporter John Markoff\n\n.\n\n.\n\n* [Alan Kay,](https://en.wikipedia.org/wiki/Alan_Kay) (recipient of the Turing Award), designer of Smalltalk, coined the term \"object oriented programming\" to describe what Smalltalk does.\n\n* [Dan Ingalls](https://en.wikipedia.org/wiki/Dan_Ingalls) (recipient of the Grace Hooper Award), is credited with inventing BitBlt, the basis of modern bit-mapped computer graphics and implemented myriad versions of the Smalltalk virtual machine over a 30 year period, from Smalltalk-76 to Squeak VM 4.\n\n* [Adele Goldberg](https://en.wikipedia.org/wiki/Adele_Goldberg_(computer_scientist\\)) was lead documenter for and wrote the first book on Smalltalk. She was President of the Association of Computing Machinery (ACM) from 1984 to 1986, and together with Kay and Ingalls, received the ACM Software Systems Award in 1987 for her work on Smalltalk.", "score": 13}, {"text": "MATE: Interactive Program Analysis with Code Property Graphs. ", "score": 50}, {"text": "Help making simplest explanation of why this is a context sensitive grammar. I am making a class of languages using a compiler compiler I wrote called Grammar ([https://jtree.treenotation.org/designer/](https://jtree.treenotation.org/designer/)), that as I understand it would be called \"Context Sensitive\" languages. Here is a very simple example Markdown alternative language called Scroll you can play with: [https://try.scroll.pub/](https://try.scroll.pub/)\n\nWhen I attempted to build a sublime syntax highlighting plugin, I ran into a roadblock with every strategy I attempted. I think perhaps this is because these languages are \"Context Sensitive\", and not Context Free, and most syntax highlighting engines are built for CFGs. Building one for CodeMirror was really easy, however, and perhaps that means it's better for Context Sensitive langs.\n\nAnyway, I am struggling to come up with a simple, 1-3 line explanation that explains why these languages are Context Sensitive. The terms are a little outside my wheelhouse. Anyone an expert with the CFG lingo and can help?", "score": 33}, {"text": "The Toxic Culture of Rejection in Computer Science. ", "score": 175}, {"text": "Official website of the software design paradigm DCI has been updated. If you're interested in becoming a better programmer, learning and understanding DCI (Data, Context, Interaction) is a thought-provoking endeavour that you won't regret.\n\nThe official DCI website [https://fulloo.info](https://fulloo.info) is now available in an updated version, packed with information about how to reach the following key aspects:\n\n* Separating what the system is (data) from what it does (function). Data and function have different rates of change so they should be separated, not as it currently is, put in classes together.\n* Create a direct mapping from the user's mental model to code. The computer should think as the user, not the other way around.\n* Make system behavior a first class entity.\n* Great code readability with no surprises at runtime.\n\nHaving spent over 10 years on the frontier of this paradigm, I'm available to answer any questions you might have about DCI.", "score": 0}, {"text": "What is the relationship between P^#P and P^FNP?. ", "score": 3}, {"text": "Artificial intelligence (AI) - the system needs new structures -.  **#Artificial #intelligence (#AI)  - the #system needs #new #structures -**   \n\n  \n  **Construction 3**    \n\n3. Basic thesis: The #structural #change from the supposed \"#objectivity\" to a \"#second #order #cybernetics\" and  4. Basic thesis: The #structural #change from #dualism to a \"#polycontexturality\"   \n    \n  This article represents \"construction 3\" of my entire essay \"The system needs new structures - not only for / against artificial intelligence (AI)\" (https://philosophies.de/index.php/2021/08/07/das-system-braucht-neue-strukturen/) and forms the conclusion to the trilogy of \"philosophy of science\" (https://philosophies.de/index.php/category/wissenschaftstheorie/) \n\n    \n  This 3rd part deals with the \"3. Basic thesis: The structural change from the supposed \"objectivity\" to a \"second order cybernetics\" and the \"4. Basic thesis: The structural change from dualism to a polycontexturality \".     \n \n\n**More at:** [**https://philosophies.de/index.php/2021/08/14/das-system-braucht-neue-strukturen/**](https://philosophies.de/index.php/2021/08/14/das-system-braucht-neue-strukturen/)", "score": 0}, {"text": "How undecidable is it to determine whether a Turning machine has infinitely many non halting inputs?. In terms of arithmetical hierarchy determining whether an arbitrary Turning machine halts for every input is \u03a0\u2082\u2070-complete.So the above problem should be at least as hard as the halting on every input. But is it more undecidable than it?", "score": 49}, {"text": "Map of Computer Science. ", "score": 1463}, {"text": "[Research] incremental algorithm to guess a dynamically changing unbound real number based on boolean hints (less/greater). **alternative title:** online algorithm to estimate a running median of the non-stationary stochastic process based on boolean feedback (less/greater)\n\nDid you ever try to guess a real number from poor binary hints like \"less\" / \"greater\"?\n\nAnd what if the conceived number is keeping changing during you guess it?\n\nThis \"simple\" problem landed to my desk for the first time somewhere around 2010, but I didn't fully solve it those days.\n\nThis year I took up this \"simple\" problem and was slightly surprised at how many difficult and interesting things were hidden in it.\n\nHere is the first starting [post](https://khamenya.notion.site/Guessing-a-real-number-by-binary-response-5ba9bd997f514ec4b4cdc2ae2322f39d) on the subject.\n\nSome highlights of our solution:\n\n1. O(1) operations per incremental step. O(1) memory usage.\n2. the solution has the much-desired fundamental property of *open-endedness*.\n3. as a bonus, it turns out that the solution is not too bad at approximating the median of the distribution of a real random variable, relative to which the environment gives us the binary hint/feedback.  And in essence this means:\n\nthe fundamental possibility of estimating the *distribution* of a real random variable from a binary response, including those random variables whose mean is uncertain, like for the Cauchy distribution.\n\nIf there is enough interest in this topic, we will write more on this topic, e.g.\n\n* how could one use it to assess distributions of random variables\n* why it could be helpful to create adaptive activation function for the neural networks\n* how does this algorithm look like for 2D case where the binary hint is \"hotter/colder\" guiding us on each guess.", "score": 22}, {"text": "[Algorithm] Minimum number of nails for planks. There is a Codility exercise where you are supposed to find the  minimum number of nails needed to nail a set of planks that have overlaps and each nail can be used to nail multiple overlapping planks:\n\n[https://app.codility.com/programmers/lessons/14-binary\\_search\\_algorithm/nailing\\_planks/](https://app.codility.com/programmers/lessons/14-binary_search_algorithm/nailing_planks/)\n\nThe Codility problem has some restriction on the exact size of the nails and the order in which they should be used, which allows the problem to be solved using binary search in polynomial time. However, I'm trying to see of the more general case where the nails can be at any position has a polynomial solution.\n\ne.g. The if the planks are \\[0,4\\], \\[2, 5\\], \\[5, 8\\], then we need at least two nails, one for \\[0, 4\\] and \\[2, 5\\] which can be at any position between \\[2, 4\\] and then one for \\[5, 8\\].\n\nThe first idea I thought of was to first determine the overlap of the planks and then you'd need as many nails as the overlaps; however, that doesn't work because you can build your overlaps in different orders e.g. if the planks are \\[0,4\\], \\[2, 5\\], \\[4, 6\\],  \\[5, 8\\], then you can have three different sets of overlaps \\[2, 4\\] and \\[5, 6\\] or \\[0, 4\\] and \\[4, 5\\] and \\[5, 8\\] or \\[4, 5\\] and \\[5, 6\\] and so will need different number of nails depending on how you want to consider the overlaps. So perhaps the question can be reduce to: what is the minimum number of overlaps that are required to cover a set of a range of numbers?", "score": 1}, {"text": "Melvyn Bragg and guests (his expert biographer Andrew Hodges, Simon Schaffer and Leslie Ann Goldberg) discuss Alan Turing (1912-1954) whose 1936 paper 'On Computable Numbers' effectively founded computer science. (Links and reading material available).. ", "score": 163}, {"text": "Bioinformatics tutorials that might be helpful to people! [xpost from r/bioinformatics, thought cs people may also be interested!]. ", "score": 23}, {"text": "System Design course for everyone! (free). Hi everyone, today I open-sourced my free System Design course which is suitable for all levels.\n\nThis course also covers everything from basics to advanced topics of system design along with interview problems such as designing Twitter, WhatsApp, Netflix, Uber, and much more!\n\nI hope this course provides a great learning experience.\n\nLink: [https://github.com/karanpratapsingh/system-design](https://github.com/karanpratapsingh/system-design)", "score": 421}, {"text": "Build a WebAssembly Language for Fun and Profit. ", "score": 37}, {"text": "py-microdots and the Anoto Codec. ", "score": 0}, {"text": "Turing Completeness Unifies Eastern and Western Mysticism. ", "score": 0}, {"text": "VkFFT now supports Rader's algorithm - A100 and MI250 benchmarks. Hello, I am the creator of the [VkFFT](https://github.com/DTolm/VkFFT) \\- GPU Fast Fourier Transform library for Vulkan/CUDA/HIP/OpenCL and Level Zero. In the latest update, I have implemented my take on Rader's FFT algorithm, which allows VkFFT to do FFTs of sequences representable as a multiplication of primes up to 83, just like you would with powers of two.\n\n[Rader's FFT algorithm](https://en.wikipedia.org/wiki/Rader%27s_FFT_algorithm) represents an FFT of prime length sequence as a convolution of length N-1. Inlining these convolutions as a step in the Stockham algorithm, makes it possible to have radix kernels of extremely high prime lengths - VkFFT currently uses primes up to 83.\n\nPreviously, VkFFT had to switch to Bluestein's algorithm if a sequence had primes bigger than 13. Bluestein's algorithm does FFT of arbitrary length as a zero-padded convolution of a length at least 2N-1. The main disadvantages of this approach are accuracy and performance dropping 2-4x times (as it has a 4-8x number of computations).\n\nRader's algorithm can solve both issues. It removes the 2-4x padding requirement by having a bigger range of primes allowed in decomposition. And depending on the Rader implementation, it reduces the number of computations.\n\nThere are two possible ways to do Rader's algorithm: direct multiplication convolution or convolution theorem. Currently, VkFFT has the first implemented as the calculation cost is low for primes up to 100. Convolution theorem implementation will be covered in the next progress update.\n\nNow let's move on to implementation details and benchmarks, starting with Nvidia's A100(40GB) and Nvidia's cuFFT. The benchmark used is a batched 1D complex to complex FFT for sizes 2-1024. We use the achieved bandwidth as a performance metric -  it is calculated as total memory transferred (2x system size) divided by the time taken by an FFT, so the higher - the better. A100 VRAM memory copy bandwidth is \\~1.3TB/s. VkFFT uses CUDA API.\n\nhttps://preview.redd.it/zrvdqm4xjci91.png?width=2896&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d695c7ac98329a09cfd04203bde164fc1df4233e\n\nAs was shown in previous posts, both VkFFT and cuFFT are almost at peak bandwidth for radix 2-13 decomposable sequences (pink/blue linear pattern near 1.3TB/s). VkFFT has better Bluestein implementation (red/black linear pattern on the bottom, min 200GB/s for cuFFT, min 400GB/s for VkFFT).\n\nNow to the main topic of this post - sequences that are divisible by primes from 2-127. It is clear from the structure that cuFFT doesn't use Bluestein's algorithm for them. And it can be seen that the bandwidth is locked at 600, 400 or 300GB/s - almost constant across the range. This can be explained that cuFFT uses multiple uploads dependent on the prime decomposition. So sequence 31 has one prime - it is done at 1.2-13GB/s bandwidth. Sequence 62, however, has two primes - 2 and 62, so it is done in two uploads - so if the algorithm is bandwidth limited, max achieved bandwidth will be 600. For a sequence 722=2\\*19\\*19, there will be three uploads and bandwidth will be 400 (\\~1300/3), etc.\n\nVkFFT has an improved version of Rader's FFT algorithm. It treats the Rader kernels as a part of the Stockham algorithm and inlines them in the generated code. So all FFTs on the tested range are done in a single upload to the chip and the peak achievable bandwidth is 1.3TB/s. Well, doing convolutions by direct multiplications is still expensive in this case, so VkFFT is not at 1.3TB/s for all of them, but most sequences have performance in the range 600-1200GB/s, which is close.  After prime 89, Bluestein's algorithm (which also has a good implementation in VkFFT) matches the complexity of multiplication Rader, so VkFFT switches to it.\n\nNow coming to AMD's MI250(single chip version), the peak copy bandwidth is 1.3TB/s. The same benchmark configuration. VkFFT uses HIP API.\n\nhttps://preview.redd.it/cw0wmd8yjci91.png?width=2896&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c3b36c50c2f9ba0ae943300b1d2b001dea063923\n\nThe same analysis as for A100 holds for MI250, except that rocFFT doesn't have Rader's algorithm and switches to Bluestein's algorithm more often. VkFFT is able to generate optimized FFT kernels for both HPC GPUs.\n\nHopefully, this post about how GPU compute libraries work under the hood was interesting, and stay tuned for the next blog post about the convolution theorem version of Rader FFT, where I will be inlining full FFT+iFFT sequences in the generated radix kernels, which will be inlined in Stockham FFT!", "score": 45}, {"text": "Beautiful Visual Proof for the sum 1^2+...+n^2=n(n+1)(2n+1)/6 with the Python library manim. ", "score": 103}, {"text": "The decommoditization of protocols. ", "score": 34}, {"text": "Is there a generalization of Sardinas\u2013Patterson's algorithm on codes with arbitrary repeatable symbols?. I wonder if there is a polynomial algorithm for solving such problem:\n\nConsider a template of string consists of symbols and symbols with stars.\nSymbol without star means that there should be this symbol at corresponding\nposition in string, symbol with star means that there should be zero or more \nsymbols. So template 'ab*a*a' matches 'aba', 'abbba', 'aa' but not 'ab' or 'a'.\n\nWe have `N` templates, each is no longer than `L` symbols. Is there a polynomial\nalgorithm to determine if every string has no more than one way to be split at\nsuch way that every part is matched by some of templates?", "score": 32}, {"text": "[Research] Deep Critical Learning (i.e., Deep Robustness) In The Era of Big Data. ", "score": 29}, {"text": "Question on general theoretical / practical limits of program validation and/or run-time behavior prediction of a specific program in a specific context (game modding!). While I'm familiar at the undergrad/enthusiast level with the general theory involved in terms of decidability, rice's theorem (I think this applies here?), formal methods etc I'm not entirely sure what specific terms/definitions this question should be couched in so I'll try walking through what I want to know about the problem I'm working on.\n\nI recently started gaming again after a long break and the game I've been playing has an absolutely thriving modding community, the game was built from the ground up with them in mind so it has a very powerful modding toolkit and handles heavy modding like a champ. But of course crashes still happen.\n\nThis has had me thinking a lot about game modding as a technical problem because from what I know about stuff like constraint-satisfaction, schema normal-forms, compilers in general etc I would think it should be possible to predict whether a mod or combination of mods will break the game given a few conditions. So I'm not sure why that's not being done already.\n\nIn terms of high level theory as a game it has a game-state, and a set of rules defining valid state transitions. The modding tools are essentially allowing players to add, remove, or modify rules. A broken mod or an interaction between two working but incompatible mods creates a bad transition to an invalid state and crashes the game.\n\nEven if can't predict whether \\*all\\* possible transitions or sequence of transitions will end in a valid state, there should be plenty of low hanging fruit that would make a huge difference.\n\nSome concrete examples I have in mind that could be handled by simply parsing the modules and checking a set of conditions.\n\n1. Two modules attempt to modify the same variable via the same API  method at the same defined point of time in the game creating a race condition. The game could show a warning, disable one (silently or otherwise), or apply the modifications in an explicit sequence.\n2. Module A totally redefines game system XYZ, module B changes system QRS but references a variable from the original XYZ which no longer exists. Again you could simply disable one, show a warning, or even better enforce some convention on module A that let's B get it's variable without having to know or care about A.\n3. Module A redefines system XYZ, module B also redefines XYZ. If we can see they are both calling the same API method to do so, disable one while the other is active.\n4. A module created a UI component with a button that will cause a bad transition if clicked during a certain time. We can see the UI component and button are using a specific API method to do this, so automatically disable the module and it's UI components during those specified times.\n\nIf you could prevent those... you'd be preventing the vast, vast majority of crashes/bugs caused by mods beyond simple \"broken module with basic programming errors.\" And these seem like things that could be handled by a script passing over the folder where the modules are stored.\n\nSo my question is, what exactly am I missing seeing as how I have \\*never\\* seen this sort of functionality implemented before?", "score": 28}, {"text": "Computation and Category Theory. \"In a recent talk, David Spivak, my advisor at Topos Institute, described Poly as \u201cthe language of computation\u201d, due to its facility in describing concepts in computer science such as data migration, dependent types, and Turing machines.\". ", "score": 76}, {"text": "Islands of Interactivity \u2014 What are They and Why is Fresh using them?. ", "score": 2}, {"text": "Made a computer vision basketball referee. ", "score": 1114}, {"text": "Function that isn't known to be primitive-recursive?. Is there a fn that hasn't been proven to be primitive? and there's a lot of evidence that *suggests* it's non-primitive, but since nobody has proven nor disproven, it's just a conjecture?\n\n(I'm sorry for my bad english)", "score": 24}, {"text": "Collaborate with a genetic algorithm to design a car - we made a toy to try and investigate how humans can collaborate with computers and playing with it helps our research!. ", "score": 105}, {"text": "Theoretical limit of type safety in a dynamically typed language?. For the purposes of this post, dynamically typed languages are languages in which a variable can be reassigned to values of different types freely and type safety refers to a more nebulous idea that type errors are checked and prevented in an effective way as possible. \n\nMy question is if we are to assume that a language is dynamically typed, what is the optimal set of rules such that type safety is maximized? Is there a language today that gets close to or achieves this?", "score": 21}, {"text": "AI-generated text is not yet at the stage of being a reliable co-author for your writing projects. But it can be a great source of inspiration and get you started on a new topic. It can be as simple as supplying the title to a language model like GPT-3.. ", "score": 194}, {"text": "Graphical notation for lambda calculus. I recently learned about lambda calculus and was wondering how to represent it more visually. There are multiple suggestions [1](https://dkeenan.com/Lambda/) [2](https://tromp.github.io/cl/diagrams.html) [3](https://bntr.planet.ee/lambda/work/visual_lambda.pdf) [4](https://arxiv.org/pdf/1305.5786.pdf) [5](https://piedeleu.com/posts/diagrammatic-lambda-calculus/) [6](https://csvoss.com/circuit-notation-lambda-calculus), but they did not seem to be simple enough.\n\nSo I made my own attempt. It is a straightforward translation just with the lambda variable after the expression:\n\n    Abstraction: /x.M\n    M\u2500x\n    \n    Application: (f x)\n    f\u2500\u2510\n      x\n\nEffectively, abstraction has a horizontal input line and application always a vertical input line. Some common expressions are\n\n    0: /f./x.x\n    x\u2500x\u2500f\n    \n    1: /f./x.(f x)\n    f\u2500\u252c\u2500x\u2500f\n      x    \n    \n    2: /f./x.(f (f x))\n    f\u2500\u252c\u2500\u2500\u2500x\u2500f\n      f\u2500\u2510    \n        x    \n    \n    succ: /n./f./x.(f ((n f) x))\n    f\u2500\u252c\u2500\u2500\u2500\u2500\u2500x\u2500f\u2500n\n      n\u2500\u252c\u2500\u2510      \n        f x      \n    \n    Y: /g.(/x.(g (x x)) /x.(g (x x)))\n    g\u2500\u252c\u2500\u2500\u2500x\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500g\n      x\u2500\u2510   g\u2500\u252c\u2500\u2500\u2500x  \n        x     x\u2500\u2510    \n                x    \n    \n    Omega: (/x.(x x) /x.(x x))\n    x\u2500\u252c\u2500x\u2500\u2510    \n      x   x\u2500\u252c\u2500x\n            x  \n\nBeta reduction is\n\n    M\u2500x\u2500\u252c\u2500...     \u2500\u2500&gt;      M[x:=N]\u2500\u2500...\n        N\n\nwhere the lambda variable and the function argument are next to each other.\n\nThis can be neatly shown in terminal environments. Here is [some code](https://gist.github.com/Gerenuk/0785c9414b5eb850e75b7e4dab2d316e) to create these representations (if you know how to improve my parsing grammar to avoid some parenthesis, please let me know).\n\nFor handwriting one could omit all horizontal lines: [Succ 1 -&gt; 2](https://i.postimg.cc/MzmVcNKc/lambda.jpg)\n\nDoes that work? Any suggestions?", "score": 60}, {"text": "AI Research: the Corporate Narrative and the Economic Reality. ", "score": 76}, {"text": "Would you trust a robot to examine, diagnose and prescribe a treatment for you? Would you trust a robot as your physician or surgeon, if your doctor or family or friends suggests? \u2013 A Study on Human \u2013 AI trust.. Hi Everyone,\n\nI am a Masters student at the De Montfort University, currently researching on Human trust on Artificial Intelligence. This research study is a short online survey investigating the factors influencing human trust on Artificial Intelligence, especially on Artificial Intelligence applications on healthcare considering the responded personal characteristics. The study has been approved by the University. If you are above 18 years please consider taking part in this research survey by clicking on below link. \n\n[https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV\\_09wI65OOmXZwFDw](https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_09wI65OOmXZwFDw)\n\nThank you for participating.", "score": 84}, {"text": "The many flavors of hashing. ", "score": 46}, {"text": "A method for designing loot drop percentages.  Many video games have a tell-tale sign of poor comprehension: The +10% buff/nerf/loot drop. This 'invention' contains no real measurement, a stand-in likely to need substantial testing before adequate data is collected to inform a better choice. Worse yet, attempts at adjustment are likely to be made just once or twice, after which labor is expended elsewhere regardless of success of the model.\n\nAt the heart of this issue is the use of unit-less percentages, which while necessary are also fairly opaque to the desires of the developer.\n\nThis article discusses a method of calculating that percentage based on a desired number of tries, along with an implementation of that method.\n\n[Loot Drops by Design](https://fourth-baryonyx-e1c.notion.site/Loot-Drops-by-Design-8d7595a8332047eba78f3ec354c2851e)", "score": 84}, {"text": "[Off-Topic] The 2nd Reddit Robotics Showcase is this Weekend!. \n# Saturday 30th &amp; Sunday 31st from  10amEDT / 3pm BST \n\n\n**The Reddit Robotics Showcase is an event for all ages and abilities to share their passion for Robotics. If you want to see some world class examples of applied computer-science in research &amp; industry, come check it out!**\n\n\n# [You can find out more from the website](https://redditroboticsshowcase.wordpress.com/)\n\n# [we will be livestreaming the event to our YouTube Channel](https://www.youtube.com/channel/UCZ3_mMxmd7ZGrfVbgPPwrAg)\n\n\n## Saturday, 30th of July\n### Industrial / Automation: \u201cThe Ocado Series 600 Bot\u201d Matt Whelan, Head of Engineering, Ocado Technology \u2013 10:00 EDT (15:00 BST, 23:00 JST)\n\nhttps://www.youtube.com/watch?v=fy4vpjw_nNw\n\n### Mobile Robots: \u201cMobile Robots in the Wild\u201d Marc Hanheide, Lincoln Centre for Autonomous Systems \u2013 14:00 EDT (19:00 BST, 03:00 JST)\n\n## Sunday, 31st of July\n### Bio \u2013 Inspired Robots: \u201cEntering the maze: snake-like robots from aerospace to surgery\u201d Dr Matteo Russo \u2013 Rolls-Royce University Technology Centre (UTC) in Manufacturing and On-Wing Technology \u2013 10:00 EDT (15:00 BST, 23:00 JST)\n\nhttps://www.youtube.com/watch?v=GJoAQ1KxaVw\n\n### Human Robot Interaction: \u201cSocial Agents and Human Robot Interaction\u201d Dr Ruth Aylett of the National Robotarium \u2013 14:00 EDT (19:00 BST, 03:00 JST)\n\n\n\n\n\" The primary purpose of this event is to showcase the multitude of projects underway in the r/Robotics Reddit community. Topics range across all focuses of robotics, such as simulation, navigation, control, perception, and mechatronic design. We will use this showcase to present discussion pieces and foster conversation between active members in the robotics community around the world. The showcase will feature invited roboticists in research and industry to discuss what they see as technical challenges or interesting directions for robots. We will focus on the following topics and showcase some of the amazing work being done by amateurs and academics, students and industry professionals alike. \"", "score": 36}, {"text": "Uninterpretable AI models can still lead to justified scientific breakthroughs. ", "score": 48}, {"text": "Ethical and social risks of harm from Language Models. ", "score": 18}, {"text": "How do you see computer science changing in the next 50 years?. From whatever specialization you\u2019re in or in general. What will the languages be like? The jobs? How will the future world around computer science affect the field and how will computer science affect the world in 50 years? Just speculation is fine, I just want opinions from people who live in these spheres", "score": 147}, {"text": "History of File Systems. I am a computer noob and humbly asking for your help. I am looking on information on the Development of Files Systems, preferably in book or article form. I am specifially interested in how file systems handle file access by multiple users and how this developed. For example, when did the first **access-control lists** appear and why? Are there any alternatives to how this is done in file systems? Do we expect to use access-control lists forever? \n\nIs there any information on this? I found this article [https://arstechnica.com/gadgets/2008/03/past-present-future-file-systems/](https://arstechnica.com/gadgets/2008/03/past-present-future-file-systems/) which is fascinating, but would love to go deeper on this topic. \n\n&amp;#x200B;\n\nAnyway, I'm a bit of a noob, so any literature on the development of computers with focus on the data side would be welcome. In my experience, computing histories focus more on the processors (vacuum tubes, semiconductors and stuff) than the data side. ANY input would be greatly appreciated.", "score": 90}, {"text": "Big Tech calls for computer science to be taught in all US schools. ", "score": 296}, {"text": "Which books shaped you most as a computer scientist?. Books are a fundamental source of knowledge in any field. Same for computer scientists. \n\nWhatever domain of CS you work in, there must be some books that you remember for all the good reasons. \n\nWhat are those? And why do you love those?", "score": 304}, {"text": "Post which in general talks about functional programming and its benefits, a good read. ", "score": 76}, {"text": "World's first ultra-fast photonic computing processor using polarization. ", "score": 204}, {"text": "The NIST post-quantum crypto algorithm selection has concluded. ", "score": 152}, {"text": "Discrete Mathematics CMU course by Po-Shen Loh [Study group]. ", "score": 2}, {"text": "Information theory, a categorical perspective. ", "score": 100}, {"text": "Mark Braverman wins 2022 Abacus Medal: expands on Shannon's Information Theory. ", "score": 146}, {"text": "Why isn't memoization helpful in getting a solution for permutation that is faster than or atleast not as slow as O(n!)?. Why is the time complexity so terrible? O(n!) is the worst out there. Can someone explain in simple terms why it's not possible to use memoization to get a complexity which is a little better?\n\nEx; `{1,2,3,4,5,6}` will have 6! permutations but `{...4,5,6}` will have to permutate 3! for each permutation of `{1,2,3...}`", "score": 58}, {"text": "Book and Video lecture Suggestion for OS. I want to learn about \"how to build an Operating System\" , so guys will you please suggest me some good relevant resources.", "score": 54}, {"text": "A verified algorithm for determining the intersection point of two lists in O(1) space. ", "score": 99}, {"text": "Can lazy evaluation be emulated in a regex with only greedy evaluation?. Or, can a lazy regular expression operator be defined in terms of only greedy operators?", "score": 14}, {"text": "An app to compute the coefficients of a function development in a spherical harmonics convergent series. Hello everybody,\n\nI want to share with you a small C++ app / program I developed some time ago (and which I am maintaining) which can be used to compute the coefficients of a function development in a spherical harmonics convergent series . Spherical harmonics are a set of functions used to find a solution of the Schroedinger equation for the hydrogen atom for example, in quantum physics. The coefficients computed to find a function development (which function depends on polar and azimuthal angle in spherical coordinates) are used in many field of physics.\n\nI decided for fun to develope a program to compute them. Tell me what do you think and of course any hint is more than welcome!\n\nYou are free to send a pull request or open issues if you want, I'll feature you in the main README file, directly in the contributor list.\n\nIf you like the repo, don't forget to leave a star! Thanks.\n\nRepository link: [https://github.com/JustWhit3/SAFD-algorithm](https://github.com/JustWhit3/SAFD-algorithm)", "score": 46}, {"text": "Deriving the formula for the number of distinct de Bruijn sequences. ", "score": 1}, {"text": "ENPA is a new means to protect your password.. ", "score": 0}, {"text": "computer science eponyms. For about fifteen years I've been maintaining a [list of computer science eponyms](https://nick-black.com/dankwiki/index.php/Computer_science_eponyms) on my personal wiki. I just added the newest entry, the Tarski-Kuratowski Algorithm.  I'm sure there are a great many I'm missing (despite claiming to be the \"World's Largest(?) Collection of Computer Science Eponyms\"), and I was hoping you folks could fill in some blanks from your own domains of expertise! Feel free to just comment below.\n\n&amp;#x200B;\n\nThanks!", "score": 101}, {"text": "Is anyone interested in taking MIT's Intro to Algorithms course?. You can reply here", "score": 172}, {"text": "Computing a 3\u00d73 determinant using &lt; 9 multiplications. I\u2019ve read that it\u2019s unknown whether a 3\u00d73 determinant can be computed using fewer than 9 multiplications. [1]\n\nIf that was ever true, it\u2019s not any more. Earlier today I found a way to do it with 8 multiplications. If the matrix is\n\n    \u239ba b c\u239e\n    \u239cd e f\u239f\n    \u239dg h i\u23a0\n\nthen we can define\n\n    D = d(h-i)\n    E = e(i-g)\n    F = f(g-h)\n    G = g(e-f)\n    H = h(f-d)\n\nusing 5 multiplications, and then compute the determinant as a(E+F+G) + b(D+F+H) - c(F+G+H), using another 3 multiplications.\n\nI\u2019m interested in whether this really is a new discovery. If you know of previous work on this, I\u2019d love to hear about it.\n\n(I realise this doesn\u2019t have massive practical applications. Maaaaaaybe there are specialised geometric applications involving 3d vectors of some non-machine numeric type, like bignums or super-high-precision floats, where multiplication is a lot more expensive than addition: in cases like that, it could be a win to compute a cross-product using 5 multiplications rather than 6, even at the expense of more additions.)\n\n1. I read it in a comment by Jeffrey Shallit on [this StackExchange post](https://cstheory.stackexchange.com/questions/37017/the-minimum-number-of-arithmetic-operations-to-compute-the-determinant).", "score": 398}, {"text": "What is the reasoning for the complexity of D Type Flip Flops?. I understand that increasing a circuit's complexity makes it slower and more power-hungry.\n\nIs the reason D Type Flip Flops are used because of the instability of inputs inside of the computer? Where the inputs are sometimes switching from 0's to 1's and 1's to 0's because of external factors such as heat and other things? Can it be seen as a sort of error-handling memory device, made due to the unpredictable nature of its inputs?", "score": 2}, {"text": "[Research] Not all our papers get published, therefore it is enjoyable to see our released papers become a true foundation for other works. ", "score": 40}, {"text": "Shortest path computation in a distributed environment.. Hello everyone. I'm trying to find shortest path algorithms that can be used in distributed systems with seperate memory. Every algorithm I could find so far assume a shared memory or a PRAM model. Does anyone know of some algorithm that needs very little communication with the other compute nodes for computing the shortest path? Any pointers to such algorithms and the distribution strategy for splitting the graph among the compute nodes would be a lot of help. Thank you.", "score": 5}, {"text": "A modern discussion on the difference between data and information. ", "score": 2}, {"text": "A method for producing the smallest (known) incompressible integer for a Turing Machine with k total states.. Consider a generic positive integer, p.    To confirm whether it is compressible is quite a different question from confirming if it incompressible.    Determining compressibility may be computationally difficult, but is nearly trivial.   (more technically speaking,  the set of compressible integers is recursively enumerable). \n\nWe turn now to the more thorny problem of determining whether p is incompressible by a Turing Machine.  In general, it is impossible to confirm whether a generic integer p is Turing incompressible.  This is strongly prohibited by the halting theorem.     More technically: the set of incompressible integers is not recursively enumerable.  (even more technical: the `K(p)` function is incomputable). \n\nNevertheless, consider that Busy Beaver records have already been confirmed for  TMs with 2 symbols and k states, when k is very small  (k&lt;6).   We do not violate the Halting theorem, as the beavers are computed forwards.    This opens the possibility of finding the *least incompressible integer* for a given , state-limited TM.      \n\nLet M denote our  Turing machine with k states, and w  be the initialization string on the tape. (call w the 'program' if you like.)   Different k's would constitute different  investigations, so for the time being, fix k=5.   \n\n1  .  Initialize &lt;M,w&gt; for w=0.  Populate the rest of the cells with 0s. Run all possible M's of k states. For all halted runs, the bit patterns that appear constitute all the compressible integers. \n\n2 . Initialize &lt;M,w&gt; for w=1. Populate the rest of the cells with 0s. Run all possible M's of k states. For all halted runs, the bit patterns that appear constitute all the compressible integers.\n\n3 .  Initialize &lt;M,w&gt; for w=01. Populate the rest of the cells with 0s. Run all possible M's of k states. For all halted runs, the bit patterns with a 1 beyond the third cell are the compressible integers. \n\n4 . Initialize &lt;M,w&gt; for w=101. Populate the rest of the cells with 0s. Run all possible M's of k states. For all halted runs, the bit patterns with a 1 beyond the 4th cell are the compressible integers.\n\n.\n\n.\n\n.\n\n\nand so on.   \n\nAs larger initial w's are attempted, there must always be a lone 1 at the far right , as an indicator of the true length of the initial pattern. (in other words, we only encode odd w's in 2's complement binary).   For these smaller w's  with bit width h,  we will always see all the possible integers from o to (2^h - 1) on output.  In other words, we expect to never find any small integers that are incompressible.    The method described above is very analogous to the sieve of Eratosthenes, or a so-called *prime sieve.*  \n\n\nFor much larger w &gt;&gt; 3  ,  we will eventually find that no M of any kind ever produced a particular integer on the output, unless w was that integer, or w had a wider bit width to begin with.    In other words , there will be  \"holes\" in the catalog of binary patterns we never finished on after halting, for all M.   (analogy would be the prime numbers left over after a sieve).  \n\nWe need only find one of these holes, or integers that was missed by all the computations above.  Once in hand, we can report that this binary integer  (call it C)   is the smallest incompressible integer for  a 2-symbol 5-state Turing Machine.   The shortest program that outputs C is just C itself already initialized on the tape. \n\nHas this been done?   \n\nYour thoughts? \n\n\n\n#Aside  \n\nIn light of the above, consider the following program.  \n\n    #include &lt;cstdlib&gt;\n    #include &lt;iostream&gt;\n    using namespace std;\n    unsigned int tape=1;\n    int main( int argc, char * argv[] )\n    {    \n        unsigned int stop = atoi(argv[1]);\n        while (tape&lt;stop) { tape++; }\n        return(1);\n    }\n\nUsing the method from before, this seems to indicate that once a TM is rich enough to represent a successor function, then all integers are compressible.  Simply increment the binary patterns on the tape until the desired integer is reached and halt.    The reason why this is not the case, is because the argv[1]  is already fully present on the tape before the program is run, and so its space is accounted for.", "score": 68}, {"text": "Application of \"rotating\" the elements of a matrix?. \nFor example this \"rotate\" operation would take this matrix: \n\n1 2 3\n\n4 5 6 \n\n7 8 9 \n\nand output this:\n\n4 1 2 \n\n7 5 3\n\n8 9 6\n\n\nAnd you could repeat this multiple times for arbitrary rotations. \n\nIs there any interesting use for this operation?", "score": 37}, {"text": "New Photonic Materials Could Enable Ultra-Fast Light-Based Computing. ", "score": 121}, {"text": "Uses of R programming language. ", "score": 0}, {"text": "What are some of the fundamental problems and puzzles in computer science?. ", "score": 116}, {"text": "Continuous Unix commit history from 1970 until today. ", "score": 166}, {"text": "Information Theory Crash Course. ", "score": 39}, {"text": "Why have we reformulated the Motif Finding Problem as the equivalent Median String Problem. ", "score": 23}, {"text": "Researchers Achieve \u2018Absurdly Fast\u2019 Algorithm for Network Flow | Quanta Magazine. ", "score": 219}, {"text": "A US Supercomputer Just Broke The Exascale Barrier, Ranking Fastest in The World. ", "score": 419}, {"text": "Parsing indentation-sensitive languages without pre-processing?. Indentation-sensitive languages, like Python, Haskell, or YAML, generally seem to not be context-free: the result of parsing a line of code depends on the indentation of a previous line, and the indentation may grow arbitrarily large.\n\nFrom what I've seen, parsing such languages usually involves some form of pre-processing, like tokenizing the text in advance and inserting `INDENT` and `DEDENT` tokens where needed.\n\nBut let's say we want to parse the program in one go, without pre-processing, maybe for performance, or just to keep the whole grammar in one place. In this case it's usual to attach actions to the rules of the grammar, so we can keep track of the current indentation level and choose the next rule accordingly.\n\nUnfortunately, most such implementations are either monadic or allow running arbitrary imperative code with each rule. This makes the whole parser Turing-complete and hinders static analysis, so we can no longer check in advance if the grammar is ambiguous or optimize redundant rules.\n\nMy question boils down to the following: what is the *smallest* extension of context-free grammars which allows to keep track of indentation while *not* making the resulting parser Turing-complete and keeping it easily analyzable?\n\nAny thoughts are appreciated!", "score": 12}, {"text": "Any papers detailing attempts to build a distributed von Neumann machine?. I'm trying to find past research that details attempts to build a distributed computer in the von Neumann model. I mean a system whereby there is a single CPU spread across multiple machines with a single program counter such that a program could be run on it without knowing it was distributed.\n\nI'm not talking just about being able to compute something using multiple machines. e.g. MPI and batch systems wouldn't apply. Neither would the various distributed data storage systems.  I understand the ways such a computer would depend on the same Lamport clock principles. IOW a distributed program counter would be very much like a distributed data storage system that tracked an extremely small amount of data. I'm not interested in how the distribution works as much as I am interested in the opportunities and challenges of maintaining the von Neumann abstraction in the context of distributed computation.\n\nI'd be thankful just to know a search term I could use in Google Scholar that doesn't end up in the morass of \"distributed computING\" papers.", "score": 81}, {"text": "LL parsing with loop detection: is there a name for it?. I love parser combinators like [Parsec](https://wiki.haskell.org/Parsec), which are usually LL(1), but one thing that annoys me is their inability to handle left recursion:\n\n    term = sum | num\n    sum = term \"+\" term\n    parse(term, \"1+2+3\") // infinite loop\n\nMost parser combinators go into an infinite loop when given such a grammar.\n\nI see a simple solution which may work if the parser combinator is not monadic, e.g. it doesn't create new parsers on the fly during the parsing process.\n\nWhenever our `parse` routine attempts to consume a token, it invokes one of the parsers, which may recursively invoke other parsers. We keep a \"call stack\" of all invoked parsers and their associated positions. If we find that the parser we're trying to invoke is already in this call stack with the exact same \"path\" and position, we consider this parse a failure and another alternative is attempted. Example:\n\n    parse(term, \"1+2+3\")\n    invoke \"term\" parser at pos 0\n    invoke \"sum\" parser at pos 0\n    invoke \"term\" parser at pos 0\n    invoke \"sum\" parser at pos 0\n        ...but it's already in the call stack, so this parser fails\n    invoke \"num\" parser (the only remaining alternative in sum | num)\n    ...continue executing the first invocation of \"sum\" parser\n\nI know it's not the most efficient approach, but it would probably make parser combinators much more ergonomic to use.\n\nIs there a name for it? Are there reasons it's not widely used, apart from potentially poor performance?", "score": 70}]